{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"VdShDA_UVnmc","outputId":"acf9037e-267b-4438-95db-6a3c9836c171","execution":{"iopub.status.busy":"2022-05-28T16:15:43.330145Z","iopub.execute_input":"2022-05-28T16:15:43.330554Z","iopub.status.idle":"2022-05-28T16:15:55.602952Z","shell.execute_reply.started":"2022-05-28T16:15:43.330519Z","shell.execute_reply":"2022-05-28T16:15:55.601817Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.18.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.53)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.5.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.27.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.5.18.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.4)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"colab=False\n\nif colab:\n    from google.colab import drive\nimport pandas as pd\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport torch.optim as optim\n\nimport time\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\n\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments","metadata":{"id":"XtZAuxfvBgAg","execution":{"iopub.status.busy":"2022-05-28T16:15:55.607206Z","iopub.execute_input":"2022-05-28T16:15:55.607578Z","iopub.status.idle":"2022-05-28T16:16:04.519926Z","shell.execute_reply.started":"2022-05-28T16:15:55.607542Z","shell.execute_reply":"2022-05-28T16:16:04.518938Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"MODE_RU = True","metadata":{"id":"s-u2CMR7L7OL","execution":{"iopub.status.busy":"2022-05-28T16:16:04.521521Z","iopub.execute_input":"2022-05-28T16:16:04.522315Z","iopub.status.idle":"2022-05-28T16:16:04.528367Z","shell.execute_reply.started":"2022-05-28T16:16:04.522266Z","shell.execute_reply":"2022-05-28T16:16:04.527439Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model_name = 'DeepPavlov/rubert-base-cased' if MODE_RU else 'bert-base-multilingual-cased'","metadata":{"id":"o0hHpObYL3uj","execution":{"iopub.status.busy":"2022-05-28T16:16:04.531031Z","iopub.execute_input":"2022-05-28T16:16:04.531494Z","iopub.status.idle":"2022-05-28T16:16:04.536885Z","shell.execute_reply.started":"2022-05-28T16:16:04.531434Z","shell.execute_reply":"2022-05-28T16:16:04.535905Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"if colab:\n    drive.mount('/content/drive/')\n\n    dir = 'drive/MyDrive/BS/DATA_EXTRACTION/'\n    corp_cased = dir + 'corp_cased.csv'\nelse:\n    corp_cased = '/kaggle/input/corp-cased/corp_cased.csv'","metadata":{"id":"u2G1_LxfCUvO","outputId":"5b1e486a-6249-40c6-f2c8-57af5c271bf1","execution":{"iopub.status.busy":"2022-05-28T16:16:04.538697Z","iopub.execute_input":"2022-05-28T16:16:04.539891Z","iopub.status.idle":"2022-05-28T16:16:04.547183Z","shell.execute_reply.started":"2022-05-28T16:16:04.539845Z","shell.execute_reply":"2022-05-28T16:16:04.546222Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(corp_cased, sep='\\t', header=None, on_bad_lines='skip')\ndf.dropna(inplace=True)\n\ndf.head()","metadata":{"id":"Mg2ZVqJ8CVJs","outputId":"6129c980-c113-4e32-c8a2-eb2aa951edb0","execution":{"iopub.status.busy":"2022-05-28T16:16:04.548914Z","iopub.execute_input":"2022-05-28T16:16:04.549550Z","iopub.status.idle":"2022-05-28T16:16:05.473975Z","shell.execute_reply.started":"2022-05-28T16:16:04.549507Z","shell.execute_reply":"2022-05-28T16:16:05.473105Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                   0  \\\n0                Школа злословия учит прикусить язык   \n1      Сохранится ли градус дискуссии в новом сезоне   \n2  Великолепная Школа злословия вернулась в эфир ...   \n3   В истории программы это уже не первый ребрендинг   \n4  Сейчас с трудом можно припомнить что начиналас...   \n\n                                                   1  \n0                           NOUN NOUN VERB INFN NOUN  \n1                 VERB PRCL NOUN NOUN PREP ADJF NOUN  \n2  ADJF NOUN NOUN VERB PREP NOUN PREP ADJF NOUN P...  \n3            PREP NOUN NOUN NPRO ADVB PRCL ADJF NOUN  \n4  ADVB PREP NOUN PRED INFN CONJ VERB NOUN PREP N...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Школа злословия учит прикусить язык</td>\n      <td>NOUN NOUN VERB INFN NOUN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Сохранится ли градус дискуссии в новом сезоне</td>\n      <td>VERB PRCL NOUN NOUN PREP ADJF NOUN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Великолепная Школа злословия вернулась в эфир ...</td>\n      <td>ADJF NOUN NOUN VERB PREP NOUN PREP ADJF NOUN P...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>В истории программы это уже не первый ребрендинг</td>\n      <td>PREP NOUN NOUN NPRO ADVB PRCL ADJF NOUN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Сейчас с трудом можно припомнить что начиналас...</td>\n      <td>ADVB PREP NOUN PRED INFN CONJ VERB NOUN PREP N...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sentences = df[0].to_numpy()\ntags = df[1].to_numpy()","metadata":{"id":"G9yabIx1CWkk","execution":{"iopub.status.busy":"2022-05-28T16:16:05.475559Z","iopub.execute_input":"2022-05-28T16:16:05.475976Z","iopub.status.idle":"2022-05-28T16:16:05.483863Z","shell.execute_reply.started":"2022-05-28T16:16:05.475937Z","shell.execute_reply":"2022-05-28T16:16:05.481834Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sentences = np.array(list(map(lambda x: str(x).split(), sentences)))\ntags = np.array(list(map(lambda x: str(x).split(), tags)))","metadata":{"id":"RlDIQNOaXELT","outputId":"ebc5b98b-0b70-461a-e8be-8f45fc7827d2","execution":{"iopub.status.busy":"2022-05-28T16:16:05.485167Z","iopub.execute_input":"2022-05-28T16:16:05.486177Z","iopub.status.idle":"2022-05-28T16:16:06.622608Z","shell.execute_reply.started":"2022-05-28T16:16:05.486132Z","shell.execute_reply":"2022-05-28T16:16:06.621611Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  \"\"\"Entry point for launching an IPython kernel.\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"def build_voc_t(ttoi):\n    idx = 0\n    \n    for tags_ in tags:\n        for tag in tags_:\n            if tag not in ttoi:\n                ttoi[tag] = idx\n                idx += 1\n\ndef creator(x, y, ttoi):\n    for i in range(len(sentences)):\n        for j in range(len(sentences[i])):\n            x_elem = []\n            #word before\n            if j != 0:\n                x_elem.append(sentences[i][j - 1])\n\n            #current word\n            x_elem.append(sentences[i][j])\n\n            #word after\n            if j != len(sentences[i]) - 1:\n                x_elem.append(sentences[i][j + 1])\n\n            x.append(' '.join(x_elem))\n            y.append(ttoi[tags[i][j]])","metadata":{"id":"atPqMo8rGG6s","execution":{"iopub.status.busy":"2022-05-28T16:16:06.624104Z","iopub.execute_input":"2022-05-28T16:16:06.626200Z","iopub.status.idle":"2022-05-28T16:16:06.634781Z","shell.execute_reply.started":"2022-05-28T16:16:06.626158Z","shell.execute_reply":"2022-05-28T16:16:06.633858Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"ttoi = {}\nx = []\ny = []\n\nbuild_voc_t(ttoi)\n\ncreator(x, y, ttoi)","metadata":{"id":"uRzqy6hAGZrL","execution":{"iopub.status.busy":"2022-05-28T16:16:06.638416Z","iopub.execute_input":"2022-05-28T16:16:06.639568Z","iopub.status.idle":"2022-05-28T16:16:09.608418Z","shell.execute_reply.started":"2022-05-28T16:16:06.639518Z","shell.execute_reply":"2022-05-28T16:16:09.607357Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, stratify=y, shuffle=True)","metadata":{"id":"R2Rf0hE_pIkx","execution":{"iopub.status.busy":"2022-05-28T16:16:09.609994Z","iopub.execute_input":"2022-05-28T16:16:09.610424Z","iopub.status.idle":"2022-05-28T16:16:11.695202Z","shell.execute_reply.started":"2022-05-28T16:16:09.610381Z","shell.execute_reply":"2022-05-28T16:16:11.694033Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"aNuUxNdHO48r","execution":{"iopub.status.busy":"2022-05-28T16:16:11.696709Z","iopub.execute_input":"2022-05-28T16:16:11.697223Z","iopub.status.idle":"2022-05-28T16:16:11.769125Z","shell.execute_reply.started":"2022-05-28T16:16:11.697180Z","shell.execute_reply":"2022-05-28T16:16:11.768180Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(model_name, max_length=512, do_lower_case=False)","metadata":{"id":"v9I81olgLwfL","outputId":"b2ce86d7-d881-4f7e-b38d-2959b3ece5b3","execution":{"iopub.status.busy":"2022-05-28T16:16:11.771284Z","iopub.execute_input":"2022-05-28T16:16:11.772061Z","iopub.status.idle":"2022-05-28T16:16:13.572232Z","shell.execute_reply.started":"2022-05-28T16:16:11.772013Z","shell.execute_reply":"2022-05-28T16:16:13.571239Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.57M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"affeb55caaad46c08545fe58a50bf0e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb75ed38b2014574afb7ef1a6e07cee5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/24.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96dc4fc873424cac98b024533fbad593"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7419e5aed478436eadb693df252b2543"}},"metadata":{}}]},{"cell_type":"code","source":"x_train_enc = tokenizer(x_train, truncation=True, padding=True, max_length=512)\nx_test_enc = tokenizer(x_test, truncation=True, padding=True, max_length=512)","metadata":{"id":"0w-2-F8fQiQb","execution":{"iopub.status.busy":"2022-05-28T16:16:13.573532Z","iopub.execute_input":"2022-05-28T16:16:13.574654Z","iopub.status.idle":"2022-05-28T16:21:24.476309Z","shell.execute_reply.started":"2022-05-28T16:16:13.574624Z","shell.execute_reply":"2022-05-28T16:21:24.475350Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"temp_ids = x_train_enc['input_ids'][0]\n\nprint(temp_ids)\nprint(tokenizer.decode(temp_ids))","metadata":{"id":"Tfe_BfK_3D76","outputId":"1fc2f738-5875-46b0-c7ff-ce1fc6dbbf2d","execution":{"iopub.status.busy":"2022-05-28T16:21:24.477994Z","iopub.execute_input":"2022-05-28T16:21:24.478395Z","iopub.status.idle":"2022-05-28T16:21:25.720564Z","shell.execute_reply.started":"2022-05-28T16:21:24.478356Z","shell.execute_reply":"2022-05-28T16:21:25.718708Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"[101, 1758, 12548, 11881, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n[CLS] за звание Чемпион [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n","output_type":"stream"}]},{"cell_type":"code","source":"class PosTagDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n        item['labels'] = torch.tensor([self.labels[idx]])\n        return item","metadata":{"id":"y21VkbFYR_ZE","execution":{"iopub.status.busy":"2022-05-28T16:21:25.722105Z","iopub.execute_input":"2022-05-28T16:21:25.723033Z","iopub.status.idle":"2022-05-28T16:21:25.730717Z","shell.execute_reply.started":"2022-05-28T16:21:25.722987Z","shell.execute_reply":"2022-05-28T16:21:25.729786Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"dataset_train = PosTagDataset(x_train_enc, y_train)\ndataset_test = PosTagDataset(x_test_enc, y_test)","metadata":{"id":"g4-LG6BOUGN0","execution":{"iopub.status.busy":"2022-05-28T16:21:25.732397Z","iopub.execute_input":"2022-05-28T16:21:25.733079Z","iopub.status.idle":"2022-05-28T16:21:25.740930Z","shell.execute_reply.started":"2022-05-28T16:21:25.733037Z","shell.execute_reply":"2022-05-28T16:21:25.740050Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(dataset_train.__getitem__(0))","metadata":{"id":"hnj020NcBHZ6","outputId":"0d45c69e-30ee-42c0-abeb-40129acd15f3","execution":{"iopub.status.busy":"2022-05-28T16:21:25.743421Z","iopub.execute_input":"2022-05-28T16:21:25.744156Z","iopub.status.idle":"2022-05-28T16:21:25.753839Z","shell.execute_reply.started":"2022-05-28T16:21:25.744110Z","shell.execute_reply":"2022-05-28T16:21:25.752461Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([  101,  1758, 12548, 11881,   102,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor([0])}\n","output_type":"stream"}]},{"cell_type":"code","source":"cr_labels = []\ncr_names = []\n\nfor name, label in ttoi.items():\n    cr_labels.append(label)\n    cr_names.append(name)\n\nprint(cr_labels)\nprint(cr_names)","metadata":{"id":"V_qL2oO0UwE7","outputId":"260bf843-b059-49ee-8a0e-4f59e4f1eec8","execution":{"iopub.status.busy":"2022-05-28T16:21:25.755548Z","iopub.execute_input":"2022-05-28T16:21:25.756820Z","iopub.status.idle":"2022-05-28T16:21:25.764341Z","shell.execute_reply.started":"2022-05-28T16:21:25.756776Z","shell.execute_reply":"2022-05-28T16:21:25.763152Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n['NOUN', 'VERB', 'INFN', 'PRCL', 'PREP', 'ADJF', 'NPRO', 'ADVB', 'PRED', 'CONJ', 'Name', 'Surn', 'PRTF', 'COMP', 'NUMR', 'UNKN', 'Patr', 'INTJ', 'PRTS', 'GRND', 'Geox', 'ADJS']\n","output_type":"stream"}]},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(ttoi))\nmodel.to(device)","metadata":{"id":"T_S9kX4vQbYb","outputId":"7e61eaae-85be-43ed-aac1-27524d55e0c3","execution":{"iopub.status.busy":"2022-05-28T16:21:25.766301Z","iopub.execute_input":"2022-05-28T16:21:25.767151Z","iopub.status.idle":"2022-05-28T16:21:57.617220Z","shell.execute_reply.started":"2022-05-28T16:21:25.767107Z","shell.execute_reply":"2022-05-28T16:21:57.616393Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ee6c75cbca140fbb00dc499d613502f"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=22, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'Модель имеет {count_parameters(model):,} обучаемых параметров')","metadata":{"id":"o2TzK4IuUXcj","outputId":"4a47d0b2-d1f9-43ec-80ba-9d864f22025c","execution":{"iopub.status.busy":"2022-05-28T16:21:57.618838Z","iopub.execute_input":"2022-05-28T16:21:57.619508Z","iopub.status.idle":"2022-05-28T16:21:57.627399Z","shell.execute_reply.started":"2022-05-28T16:21:57.619449Z","shell.execute_reply":"2022-05-28T16:21:57.626391Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Модель имеет 177,870,358 обучаемых параметров\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_metrics(y_pred):\n    y_true = y_pred.label_ids\n    y_pred = y_pred.predictions.argmax(-1)\n    cl_rep = classification_report(y_pred, y_true, labels=cr_labels, target_names=cr_names) # accuracy_score - функция из sklearn.metrics\n    return {'classification report': cl_rep}","metadata":{"id":"utN5w85VMfGR","execution":{"iopub.status.busy":"2022-05-28T16:21:57.628882Z","iopub.execute_input":"2022-05-28T16:21:57.629507Z","iopub.status.idle":"2022-05-28T16:21:57.645446Z","shell.execute_reply.started":"2022-05-28T16:21:57.629442Z","shell.execute_reply":"2022-05-28T16:21:57.643970Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir = 'results/',\n    num_train_epochs = 5, # Число эпох\n    per_device_train_batch_size = 8, # Размеры пакетов обучения и оценки\n    per_device_eval_batch_size = 8,\n    warmup_steps = 100, # Шаг выдачи предупреждений\n    max_steps = 3000,\n    weight_decay = 0.01, # Коэффициент уменьшения весов\n    load_best_model_at_end = True, # Флаг загрузки лучшей модели после завершения обучения\n    logging_steps = 500, # Шаг сохранения весов (checkpoint)\n    evaluation_strategy = 'steps' # Стратегия обучения\n)","metadata":{"id":"Pm1nd-NhNA0h","execution":{"iopub.status.busy":"2022-05-28T16:22:59.432886Z","iopub.execute_input":"2022-05-28T16:22:59.433338Z","iopub.status.idle":"2022-05-28T16:22:59.447729Z","shell.execute_reply.started":"2022-05-28T16:22:59.433302Z","shell.execute_reply":"2022-05-28T16:22:59.446644Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"using `logging_steps` to initialize `eval_steps` to 500\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model = model,\n    args = training_args,\n    train_dataset = dataset_train,\n    eval_dataset = dataset_test,\n    compute_metrics = compute_metrics\n)","metadata":{"id":"hBRcaHBEN8H5","outputId":"1e819032-af43-443b-d152-417b1fde0fde","execution":{"iopub.status.busy":"2022-05-28T16:23:01.778016Z","iopub.execute_input":"2022-05-28T16:23:01.778421Z","iopub.status.idle":"2022-05-28T16:23:01.800786Z","shell.execute_reply.started":"2022-05-28T16:23:01.778387Z","shell.execute_reply":"2022-05-28T16:23:01.799860Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train() # Обучение","metadata":{"id":"QAm9XzlSN9Wp","outputId":"e72dc5ad-2fe5-415b-c4d6-32ee6986cbc6","execution":{"iopub.status.busy":"2022-05-28T16:23:04.786320Z","iopub.execute_input":"2022-05-28T16:23:04.786753Z","iopub.status.idle":"2022-05-28T18:35:25.136997Z","shell.execute_reply.started":"2022-05-28T16:23:04.786717Z","shell.execute_reply":"2022-05-28T18:35:25.135838Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 1089240\n  Num Epochs = 1\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 3000\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3000/3000 2:12:19, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Classification report</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.748200</td>\n      <td>0.626199</td>\n      <td>              precision    recall  f1-score   support\n\n        NOUN       0.93      0.97      0.95    146373\n        VERB       0.89      0.92      0.91     40145\n        INFN       0.98      0.96      0.97     11173\n        PRCL       0.71      0.48      0.57     20933\n        PREP       0.99      0.92      0.95     60017\n        ADJF       0.90      0.93      0.91     67693\n        NPRO       0.87      0.89      0.88     13640\n        ADVB       0.37      0.75      0.50      8632\n        PRED       0.00      0.00      0.00         0\n        CONJ       0.96      0.73      0.83     54352\n        Name       0.00      0.00      0.00         1\n        Surn       0.91      0.21      0.34     17843\n        PRTF       0.87      0.63      0.73      9998\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.90      0.66      0.76      3291\n        UNKN       0.00      0.41      0.00        29\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.90      0.73      0.81      3934\n        GRND       0.00      0.00      0.00         0\n        Geox       0.87      0.67      0.76      8764\n        ADJS       0.00      0.00      0.00         0\n\n    accuracy                           0.85    466818\n   macro avg       0.55      0.49      0.49    466818\nweighted avg       0.91      0.85      0.87    466818\n</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.545300</td>\n      <td>0.474206</td>\n      <td>              precision    recall  f1-score   support\n\n        NOUN       0.98      0.92      0.95    161294\n        VERB       0.93      0.95      0.94     40545\n        INFN       0.99      0.92      0.95     11852\n        PRCL       0.73      0.90      0.81     11459\n        PREP       0.98      0.98      0.98     56062\n        ADJF       0.91      0.93      0.92     68236\n        NPRO       0.94      0.71      0.81     18482\n        ADVB       0.84      0.74      0.79     20062\n        PRED       0.00      0.00      0.00         0\n        CONJ       0.94      0.94      0.94     41274\n        Name       0.57      0.89      0.69      3533\n        Surn       0.50      0.70      0.58      2903\n        PRTF       0.79      0.84      0.82      6894\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.93      0.82      0.87      2723\n        UNKN       0.46      0.55      0.50      8525\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.60      0.88      0.71      2188\n        GRND       0.76      0.90      0.83      1806\n        Geox       0.82      0.93      0.87      5946\n        ADJS       0.41      0.50      0.45      3034\n\n    accuracy                           0.90    466818\n   macro avg       0.64      0.68      0.66    466818\nweighted avg       0.92      0.90      0.91    466818\n</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.450100</td>\n      <td>0.366432</td>\n      <td>              precision    recall  f1-score   support\n\n        NOUN       0.96      0.97      0.97    151236\n        VERB       0.96      0.95      0.95     42104\n        INFN       0.98      0.98      0.98     10905\n        PRCL       0.91      0.83      0.87     15345\n        PREP       0.99      0.97      0.98     56683\n        ADJF       0.96      0.91      0.93     74105\n        NPRO       0.85      0.95      0.90     12595\n        ADVB       0.88      0.79      0.83     19559\n        PRED       0.00      0.00      0.00         0\n        CONJ       0.96      0.95      0.96     41929\n        Name       0.79      0.48      0.59      9157\n        Surn       0.00      0.00      0.00         1\n        PRTF       0.81      0.87      0.84      6810\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.87      0.91      0.89      2309\n        UNKN       0.58      0.51      0.54     11430\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.97      0.78      0.86      4000\n        GRND       0.77      0.92      0.84      1783\n        Geox       0.84      0.94      0.89      6002\n        ADJS       0.17      0.72      0.27       865\n\n    accuracy                           0.92    466818\n   macro avg       0.65      0.66      0.64    466818\nweighted avg       0.94      0.92      0.93    466818\n</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.377500</td>\n      <td>0.342883</td>\n      <td>              precision    recall  f1-score   support\n\n        NOUN       0.97      0.96      0.97    153996\n        VERB       0.95      0.97      0.96     40960\n        INFN       0.99      0.98      0.99     11047\n        PRCL       0.91      0.95      0.93     13481\n        PREP       0.99      0.98      0.99     56113\n        ADJF       0.95      0.93      0.94     71410\n        NPRO       0.92      0.92      0.92     13993\n        ADVB       0.90      0.76      0.83     20831\n        PRED       0.54      0.94      0.69       878\n        CONJ       0.95      0.98      0.97     40134\n        Name       0.75      0.74      0.75      5628\n        Surn       0.68      0.68      0.68      4076\n        PRTF       0.90      0.84      0.87      7879\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.85      0.95      0.90      2162\n        UNKN       0.48      0.60      0.53      8173\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.97      0.77      0.86      4044\n        GRND       0.78      0.95      0.86      1767\n        Geox       0.89      0.82      0.86      7401\n        ADJS       0.45      0.59      0.51      2845\n\n    accuracy                           0.93    466818\n   macro avg       0.72      0.74      0.73    466818\nweighted avg       0.94      0.93      0.94    466818\n</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.376100</td>\n      <td>0.315291</td>\n      <td>              precision    recall  f1-score   support\n\n        NOUN       0.97      0.97      0.97    153076\n        VERB       0.96      0.96      0.96     41751\n        INFN       0.99      0.97      0.98     11171\n        PRCL       0.92      0.89      0.91     14379\n        PREP       0.99      0.98      0.99     56110\n        ADJF       0.97      0.92      0.94     73033\n        NPRO       0.92      0.93      0.93     13827\n        ADVB       0.90      0.81      0.85     19489\n        PRED       0.89      0.66      0.76      2071\n        CONJ       0.96      0.97      0.97     41049\n        Name       0.76      0.79      0.77      5321\n        Surn       0.76      0.65      0.70      4782\n        PRTF       0.86      0.88      0.87      7192\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.91      0.89      0.90      2440\n        UNKN       0.44      0.68      0.53      6552\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.96      0.86      0.91      3566\n        GRND       0.81      0.91      0.86      1896\n        Geox       0.87      0.89      0.88      6582\n        ADJS       0.52      0.77      0.62      2531\n\n    accuracy                           0.94    466818\n   macro avg       0.74      0.74      0.74    466818\nweighted avg       0.94      0.94      0.94    466818\n</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.349400</td>\n      <td>0.288676</td>\n      <td>              precision    recall  f1-score   support\n\n        NOUN       0.97      0.97      0.97    153406\n        VERB       0.96      0.96      0.96     41553\n        INFN       0.99      0.98      0.98     11093\n        PRCL       0.92      0.91      0.91     14232\n        PREP       0.99      0.98      0.99     55968\n        ADJF       0.97      0.93      0.95     72202\n        NPRO       0.91      0.95      0.93     13328\n        ADVB       0.91      0.82      0.86     19406\n        PRED       0.89      0.72      0.80      1883\n        CONJ       0.97      0.97      0.97     41306\n        Name       0.74      0.83      0.78      4893\n        Surn       0.68      0.71      0.69      3898\n        PRTF       0.89      0.87      0.88      7542\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.97      0.87      0.92      2677\n        UNKN       0.55      0.62      0.58      9020\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.96      0.85      0.90      3641\n        GRND       0.81      0.91      0.86      1905\n        Geox       0.86      0.93      0.89      6260\n        ADJS       0.52      0.74      0.61      2605\n\n    accuracy                           0.94    466818\n   macro avg       0.75      0.75      0.75    466818\nweighted avg       0.95      0.94      0.94    466818\n</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 466818\n  Batch size = 8\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"              precision    recall  f1-score   support\n\n        NOUN       0.93      0.97      0.95    146373\n        VERB       0.89      0.92      0.91     40145\n        INFN       0.98      0.96      0.97     11173\n        PRCL       0.71      0.48      0.57     20933\n        PREP       0.99      0.92      0.95     60017\n        ADJF       0.90      0.93      0.91     67693\n        NPRO       0.87      0.89      0.88     13640\n        ADVB       0.37      0.75      0.50      8632\n        PRED       0.00      0.00      0.00         0\n        CONJ       0.96      0.73      0.83     54352\n        Name       0.00      0.00      0.00         1\n        Surn       0.91      0.21      0.34     17843\n        PRTF       0.87      0.63      0.73      9998\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.90      0.66      0.76      3291\n        UNKN       0.00      0.41      0.00        29\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.90      0.73      0.81      3934\n        GRND       0.00      0.00      0.00         0\n        Geox       0.87      0.67      0.76      8764\n        ADJS       0.00      0.00      0.00         0\n\n    accuracy                           0.85    466818\n   macro avg       0.55      0.49      0.49    466818\nweighted avg       0.91      0.85      0.87    466818\n\" of type <class 'str'> for key \"eval/classification report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nSaving model checkpoint to results/checkpoint-500\nConfiguration saved in results/checkpoint-500/config.json\nModel weights saved in results/checkpoint-500/pytorch_model.bin\n***** Running Evaluation *****\n  Num examples = 466818\n  Batch size = 8\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"              precision    recall  f1-score   support\n\n        NOUN       0.98      0.92      0.95    161294\n        VERB       0.93      0.95      0.94     40545\n        INFN       0.99      0.92      0.95     11852\n        PRCL       0.73      0.90      0.81     11459\n        PREP       0.98      0.98      0.98     56062\n        ADJF       0.91      0.93      0.92     68236\n        NPRO       0.94      0.71      0.81     18482\n        ADVB       0.84      0.74      0.79     20062\n        PRED       0.00      0.00      0.00         0\n        CONJ       0.94      0.94      0.94     41274\n        Name       0.57      0.89      0.69      3533\n        Surn       0.50      0.70      0.58      2903\n        PRTF       0.79      0.84      0.82      6894\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.93      0.82      0.87      2723\n        UNKN       0.46      0.55      0.50      8525\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.60      0.88      0.71      2188\n        GRND       0.76      0.90      0.83      1806\n        Geox       0.82      0.93      0.87      5946\n        ADJS       0.41      0.50      0.45      3034\n\n    accuracy                           0.90    466818\n   macro avg       0.64      0.68      0.66    466818\nweighted avg       0.92      0.90      0.91    466818\n\" of type <class 'str'> for key \"eval/classification report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nSaving model checkpoint to results/checkpoint-1000\nConfiguration saved in results/checkpoint-1000/config.json\nModel weights saved in results/checkpoint-1000/pytorch_model.bin\n***** Running Evaluation *****\n  Num examples = 466818\n  Batch size = 8\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"              precision    recall  f1-score   support\n\n        NOUN       0.96      0.97      0.97    151236\n        VERB       0.96      0.95      0.95     42104\n        INFN       0.98      0.98      0.98     10905\n        PRCL       0.91      0.83      0.87     15345\n        PREP       0.99      0.97      0.98     56683\n        ADJF       0.96      0.91      0.93     74105\n        NPRO       0.85      0.95      0.90     12595\n        ADVB       0.88      0.79      0.83     19559\n        PRED       0.00      0.00      0.00         0\n        CONJ       0.96      0.95      0.96     41929\n        Name       0.79      0.48      0.59      9157\n        Surn       0.00      0.00      0.00         1\n        PRTF       0.81      0.87      0.84      6810\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.87      0.91      0.89      2309\n        UNKN       0.58      0.51      0.54     11430\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.97      0.78      0.86      4000\n        GRND       0.77      0.92      0.84      1783\n        Geox       0.84      0.94      0.89      6002\n        ADJS       0.17      0.72      0.27       865\n\n    accuracy                           0.92    466818\n   macro avg       0.65      0.66      0.64    466818\nweighted avg       0.94      0.92      0.93    466818\n\" of type <class 'str'> for key \"eval/classification report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nSaving model checkpoint to results/checkpoint-1500\nConfiguration saved in results/checkpoint-1500/config.json\nModel weights saved in results/checkpoint-1500/pytorch_model.bin\n***** Running Evaluation *****\n  Num examples = 466818\n  Batch size = 8\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"              precision    recall  f1-score   support\n\n        NOUN       0.97      0.96      0.97    153996\n        VERB       0.95      0.97      0.96     40960\n        INFN       0.99      0.98      0.99     11047\n        PRCL       0.91      0.95      0.93     13481\n        PREP       0.99      0.98      0.99     56113\n        ADJF       0.95      0.93      0.94     71410\n        NPRO       0.92      0.92      0.92     13993\n        ADVB       0.90      0.76      0.83     20831\n        PRED       0.54      0.94      0.69       878\n        CONJ       0.95      0.98      0.97     40134\n        Name       0.75      0.74      0.75      5628\n        Surn       0.68      0.68      0.68      4076\n        PRTF       0.90      0.84      0.87      7879\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.85      0.95      0.90      2162\n        UNKN       0.48      0.60      0.53      8173\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.97      0.77      0.86      4044\n        GRND       0.78      0.95      0.86      1767\n        Geox       0.89      0.82      0.86      7401\n        ADJS       0.45      0.59      0.51      2845\n\n    accuracy                           0.93    466818\n   macro avg       0.72      0.74      0.73    466818\nweighted avg       0.94      0.93      0.94    466818\n\" of type <class 'str'> for key \"eval/classification report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nSaving model checkpoint to results/checkpoint-2000\nConfiguration saved in results/checkpoint-2000/config.json\nModel weights saved in results/checkpoint-2000/pytorch_model.bin\n***** Running Evaluation *****\n  Num examples = 466818\n  Batch size = 8\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"              precision    recall  f1-score   support\n\n        NOUN       0.97      0.97      0.97    153076\n        VERB       0.96      0.96      0.96     41751\n        INFN       0.99      0.97      0.98     11171\n        PRCL       0.92      0.89      0.91     14379\n        PREP       0.99      0.98      0.99     56110\n        ADJF       0.97      0.92      0.94     73033\n        NPRO       0.92      0.93      0.93     13827\n        ADVB       0.90      0.81      0.85     19489\n        PRED       0.89      0.66      0.76      2071\n        CONJ       0.96      0.97      0.97     41049\n        Name       0.76      0.79      0.77      5321\n        Surn       0.76      0.65      0.70      4782\n        PRTF       0.86      0.88      0.87      7192\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.91      0.89      0.90      2440\n        UNKN       0.44      0.68      0.53      6552\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.96      0.86      0.91      3566\n        GRND       0.81      0.91      0.86      1896\n        Geox       0.87      0.89      0.88      6582\n        ADJS       0.52      0.77      0.62      2531\n\n    accuracy                           0.94    466818\n   macro avg       0.74      0.74      0.74    466818\nweighted avg       0.94      0.94      0.94    466818\n\" of type <class 'str'> for key \"eval/classification report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nSaving model checkpoint to results/checkpoint-2500\nConfiguration saved in results/checkpoint-2500/config.json\nModel weights saved in results/checkpoint-2500/pytorch_model.bin\n***** Running Evaluation *****\n  Num examples = 466818\n  Batch size = 8\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"              precision    recall  f1-score   support\n\n        NOUN       0.97      0.97      0.97    153406\n        VERB       0.96      0.96      0.96     41553\n        INFN       0.99      0.98      0.98     11093\n        PRCL       0.92      0.91      0.91     14232\n        PREP       0.99      0.98      0.99     55968\n        ADJF       0.97      0.93      0.95     72202\n        NPRO       0.91      0.95      0.93     13328\n        ADVB       0.91      0.82      0.86     19406\n        PRED       0.89      0.72      0.80      1883\n        CONJ       0.97      0.97      0.97     41306\n        Name       0.74      0.83      0.78      4893\n        Surn       0.68      0.71      0.69      3898\n        PRTF       0.89      0.87      0.88      7542\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.97      0.87      0.92      2677\n        UNKN       0.55      0.62      0.58      9020\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.96      0.85      0.90      3641\n        GRND       0.81      0.91      0.86      1905\n        Geox       0.86      0.93      0.89      6260\n        ADJS       0.52      0.74      0.61      2605\n\n    accuracy                           0.94    466818\n   macro avg       0.75      0.75      0.75    466818\nweighted avg       0.95      0.94      0.94    466818\n\" of type <class 'str'> for key \"eval/classification report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\nSaving model checkpoint to results/checkpoint-3000\nConfiguration saved in results/checkpoint-3000/config.json\nModel weights saved in results/checkpoint-3000/pytorch_model.bin\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from results/checkpoint-3000 (score: 0.2886764109134674).\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3000, training_loss=0.4744397430419922, metrics={'train_runtime': 7938.1037, 'train_samples_per_second': 3.023, 'train_steps_per_second': 0.378, 'total_flos': 801810453600000.0, 'train_loss': 0.4744397430419922, 'epoch': 0.02})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate() # Оценка","metadata":{"id":"MTZyMn-V2-TJ","execution":{"iopub.status.busy":"2022-05-28T18:35:29.024037Z","iopub.execute_input":"2022-05-28T18:35:29.025585Z","iopub.status.idle":"2022-05-28T18:56:17.986134Z","shell.execute_reply.started":"2022-05-28T18:35:29.025531Z","shell.execute_reply":"2022-05-28T18:56:17.985206Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 466818\n  Batch size = 8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='58353' max='58353' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [58353/58353 20:47]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nTrainer is attempting to log a value of \"              precision    recall  f1-score   support\n\n        NOUN       0.97      0.97      0.97    153406\n        VERB       0.96      0.96      0.96     41553\n        INFN       0.99      0.98      0.98     11093\n        PRCL       0.92      0.91      0.91     14232\n        PREP       0.99      0.98      0.99     55968\n        ADJF       0.97      0.93      0.95     72202\n        NPRO       0.91      0.95      0.93     13328\n        ADVB       0.91      0.82      0.86     19406\n        PRED       0.89      0.72      0.80      1883\n        CONJ       0.97      0.97      0.97     41306\n        Name       0.74      0.83      0.78      4893\n        Surn       0.68      0.71      0.69      3898\n        PRTF       0.89      0.87      0.88      7542\n        COMP       0.00      0.00      0.00         0\n        NUMR       0.97      0.87      0.92      2677\n        UNKN       0.55      0.62      0.58      9020\n        Patr       0.00      0.00      0.00         0\n        INTJ       0.00      0.00      0.00         0\n        PRTS       0.96      0.85      0.90      3641\n        GRND       0.81      0.91      0.86      1905\n        Geox       0.86      0.93      0.89      6260\n        ADJS       0.52      0.74      0.61      2605\n\n    accuracy                           0.94    466818\n   macro avg       0.75      0.75      0.75    466818\nweighted avg       0.95      0.94      0.94    466818\n\" of type <class 'str'> for key \"eval/classification report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.2886764109134674,\n 'eval_classification report': '              precision    recall  f1-score   support\\n\\n        NOUN       0.97      0.97      0.97    153406\\n        VERB       0.96      0.96      0.96     41553\\n        INFN       0.99      0.98      0.98     11093\\n        PRCL       0.92      0.91      0.91     14232\\n        PREP       0.99      0.98      0.99     55968\\n        ADJF       0.97      0.93      0.95     72202\\n        NPRO       0.91      0.95      0.93     13328\\n        ADVB       0.91      0.82      0.86     19406\\n        PRED       0.89      0.72      0.80      1883\\n        CONJ       0.97      0.97      0.97     41306\\n        Name       0.74      0.83      0.78      4893\\n        Surn       0.68      0.71      0.69      3898\\n        PRTF       0.89      0.87      0.88      7542\\n        COMP       0.00      0.00      0.00         0\\n        NUMR       0.97      0.87      0.92      2677\\n        UNKN       0.55      0.62      0.58      9020\\n        Patr       0.00      0.00      0.00         0\\n        INTJ       0.00      0.00      0.00         0\\n        PRTS       0.96      0.85      0.90      3641\\n        GRND       0.81      0.91      0.86      1905\\n        Geox       0.86      0.93      0.89      6260\\n        ADJS       0.52      0.74      0.61      2605\\n\\n    accuracy                           0.94    466818\\n   macro avg       0.75      0.75      0.75    466818\\nweighted avg       0.95      0.94      0.94    466818\\n',\n 'eval_runtime': 1248.9475,\n 'eval_samples_per_second': 373.769,\n 'eval_steps_per_second': 46.722,\n 'epoch': 0.02}"},"metadata":{}}]}]}