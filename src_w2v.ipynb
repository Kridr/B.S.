{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe6Cs8n4uKRQ",
        "outputId": "85dc1766-d214-47a4-e87d-079621d8b357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymorphy2[fast] in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Requirement already satisfied: DAWG>=0.8 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymorphy2[fast]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzL9GPKra1Nw"
      },
      "source": [
        "Импортируем библоитеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OWwej54saLSE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from nltk.stem.snowball import RussianStemmer\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLLLiXUQa5eA"
      },
      "source": [
        "#Часть 1. Чтение данных и первичная предобработка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9HsHUFMbFQQ"
      },
      "source": [
        "В программе будет три режима работы:\n",
        "1.   Без уменьшения словаря\n",
        "2.   Стемминг\n",
        "3.   Лемматизация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KJe5ClYi7Kr9"
      },
      "outputs": [],
      "source": [
        "REDUCTION_MODE = 2 #0 - no reduction, 1 - stemming, 2 - lemmatize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR3-c3Vebjzw"
      },
      "source": [
        "Подключаем гугл диск, где содержится файл с корпусом, который был получен ранее"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WULuCwwH9LJs",
        "outputId": "639b466a-f2c9-4527-be6c-914af9a942f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive/')\n",
        "\n",
        "dir = 'drive/MyDrive/BS/DATA_EXTRACTION/'\n",
        "corp_cased = dir + 'corp_cased.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F03tQFjbznw"
      },
      "source": [
        "Считываем csv файл корпуса и выводим первые пять элементов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AOIpuBdx9TU0",
        "outputId": "5dd3aaa6-2384-4b2f-f7f0-8d862cbf2f27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0  \\\n",
              "0                Школа злословия учит прикусить язык   \n",
              "1      Сохранится ли градус дискуссии в новом сезоне   \n",
              "2  Великолепная Школа злословия вернулась в эфир ...   \n",
              "3   В истории программы это уже не первый ребрендинг   \n",
              "4  Сейчас с трудом можно припомнить что начиналас...   \n",
              "\n",
              "                                                   1  \n",
              "0                           NOUN NOUN VERB INFN NOUN  \n",
              "1                 VERB PRCL NOUN NOUN PREP ADJF NOUN  \n",
              "2  ADJF NOUN NOUN VERB PREP NOUN PREP ADJF NOUN P...  \n",
              "3            PREP NOUN NOUN NPRO ADVB PRCL ADJF NOUN  \n",
              "4  ADVB PREP NOUN PRED INFN CONJ VERB NOUN PREP N...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34982e48-ea9b-4562-9e46-421ff225ff59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Школа злословия учит прикусить язык</td>\n",
              "      <td>NOUN NOUN VERB INFN NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Сохранится ли градус дискуссии в новом сезоне</td>\n",
              "      <td>VERB PRCL NOUN NOUN PREP ADJF NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Великолепная Школа злословия вернулась в эфир ...</td>\n",
              "      <td>ADJF NOUN NOUN VERB PREP NOUN PREP ADJF NOUN P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>В истории программы это уже не первый ребрендинг</td>\n",
              "      <td>PREP NOUN NOUN NPRO ADVB PRCL ADJF NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Сейчас с трудом можно припомнить что начиналас...</td>\n",
              "      <td>ADVB PREP NOUN PRED INFN CONJ VERB NOUN PREP N...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34982e48-ea9b-4562-9e46-421ff225ff59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34982e48-ea9b-4562-9e46-421ff225ff59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34982e48-ea9b-4562-9e46-421ff225ff59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv(corp_cased, sep='\\t', header=None, on_bad_lines='skip')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Удаялем строки с nan значениями"
      ],
      "metadata": {
        "id": "GKUJIAF-EmFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "x6x_OmcRDyr1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EOHrtjQdGzFb"
      },
      "outputs": [],
      "source": [
        "stemmer = RussianStemmer()\n",
        "lemmatizer = MorphAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7kr_wTOb-7Y"
      },
      "source": [
        "Определяем функцию, которая исходя из режима работы делает соотвестующие преобразования слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lzLqDhbz_TI-"
      },
      "outputs": [],
      "source": [
        "def reduction(x):\n",
        "    x = str(x)\n",
        "    if REDUCTION_MODE == 0:\n",
        "        return x.split()\n",
        "    elif REDUCTION_MODE == 1:\n",
        "        return [stemmer.stem(token) for token in x.split(' ')]\n",
        "    elif REDUCTION_MODE == 2:\n",
        "        return [lemmatizer.normal_forms(token)[0] for token in x.split(' ')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRPa8OUScGyI"
      },
      "source": [
        "Используем функцию выше"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1teZPfiNQLr",
        "outputId": "a022bf19-d1a4-4541-82ea-dd92b1dfbcfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[list(['школа', 'злословие', 'учить', 'прикусить', 'язык'])\n",
            " list(['сохраниться', 'ли', 'градус', 'дискуссия', 'в', 'новый', 'сезон'])\n",
            " list(['великолепный', 'школа', 'злословие', 'вернуться', 'в', 'эфир', 'после', 'летний', 'каникулы', 'в', 'новый', 'формат'])\n",
            " list(['в', 'история', 'программа', 'это', 'уже', 'не', 'первый', 'ребрендинг'])\n",
            " list(['сейчас', 'с', 'труд', 'можно', 'припомнить', 'что', 'начинаться', 'школа', 'на', 'канал', 'культура', 'как', 'стандартный', 'ток-шоу', 'который', 'отличаться', 'от', 'другой', 'кухонный', 'обсуждение', 'гость', 'что', 'называться', 'за', 'глаз', 'и', 'неожиданный', 'персона', 'в', 'качество', 'ведущий'])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "sentences = df[0].to_numpy()\n",
        "\n",
        "sentences = np.array(list(map(reduction, sentences)))\n",
        "\n",
        "print(sentences[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSsnmhUIcKOA"
      },
      "source": [
        "Также разделяем теги на токены"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rp79vyIXEGb",
        "outputId": "4cdc5cd9-2373-413a-f962-0099b085d999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[list(['NOUN', 'NOUN', 'VERB', 'INFN', 'NOUN'])\n",
            " list(['VERB', 'PRCL', 'NOUN', 'NOUN', 'PREP', 'ADJF', 'NOUN'])\n",
            " list(['ADJF', 'NOUN', 'NOUN', 'VERB', 'PREP', 'NOUN', 'PREP', 'ADJF', 'NOUN', 'PREP', 'ADJF', 'NOUN'])\n",
            " list(['PREP', 'NOUN', 'NOUN', 'NPRO', 'ADVB', 'PRCL', 'ADJF', 'NOUN'])\n",
            " list(['ADVB', 'PREP', 'NOUN', 'PRED', 'INFN', 'CONJ', 'VERB', 'NOUN', 'PREP', 'NOUN', 'NOUN', 'CONJ', 'ADJF', 'NOUN', 'ADJF', 'VERB', 'PREP', 'ADJF', 'ADJF', 'NOUN', 'NOUN', 'CONJ', 'VERB', 'PREP', 'NOUN', 'CONJ', 'ADJF', 'NOUN', 'PREP', 'NOUN', 'ADJF'])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "tags = df[1].to_numpy()\n",
        "\n",
        "tags = np.array(list(map(lambda x: str(x).split(), tags)))\n",
        "\n",
        "print(tags[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cpEeNgUcolg"
      },
      "source": [
        "Создаем Word2Vec модель из имеющихся предложений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "P8_ypRR3XFGD"
      },
      "outputs": [],
      "source": [
        "size, window, min_cnt, sg = 30, 2, 2, 0 # Используем модель CBOW\n",
        "workers = multiprocessing.cpu_count()\n",
        "n_iter = 150\n",
        "w2v_model = Word2Vec(sentences, size = size, window = window, min_count = min_cnt,\n",
        "                    sg = sg, workers = workers, iter = n_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty1kBtgHczZ4"
      },
      "source": [
        "# Часть 2. Подготовка датасетов для моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn9FkzRhc5eo"
      },
      "source": [
        "Создаем функции для создания словарей слов и тегов (чтобы перевести текст в цифру), а также создаем модель для классификатора\\\n",
        "[слово_до, слово, слово_после] -> часть речи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "b8I53BK-iICH"
      },
      "outputs": [],
      "source": [
        "def build_voc_w(stoi):\n",
        "    idx = 1\n",
        "\n",
        "    for sentence in sentences:\n",
        "        for word in sentence:\n",
        "            if word not in stoi:\n",
        "                stoi[word] = idx\n",
        "                idx += 1\n",
        "\n",
        "\n",
        "def build_voc_t(ttoi):\n",
        "    idx = 0\n",
        "    \n",
        "    for tags_ in tags:\n",
        "        for tag in tags_:\n",
        "            if tag not in ttoi:\n",
        "                ttoi[tag] = idx\n",
        "                idx += 1\n",
        "\n",
        "def creator(x, y, stoi, ttoi):\n",
        "    for i in range(len(sentences)):\n",
        "        for j in range(len(sentences[i])):\n",
        "            x_elem = []\n",
        "            #word before\n",
        "            if j == 0:\n",
        "                x_elem.append(0)\n",
        "            else:\n",
        "                x_elem.append(stoi[sentences[i][j - 1]])\n",
        "\n",
        "            #current word\n",
        "            x_elem.append(stoi[sentences[i][j]])\n",
        "\n",
        "            #word after\n",
        "            if j == len(sentences[i]) - 1:\n",
        "                x_elem.append(0)\n",
        "            else:\n",
        "                x_elem.append(stoi[sentences[i][j + 1]])\n",
        "\n",
        "            x.append(x_elem)\n",
        "            y.append(ttoi[tags[i][j]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K9kuWSmdUuo"
      },
      "source": [
        "Применяем определенные выше функции. Нулевой индекс оставляем для выравнивания"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BTPKhFrviVUX"
      },
      "outputs": [],
      "source": [
        "#sentences vocs\n",
        "stoi = {None: 0}\n",
        "\n",
        "#tags vocs\n",
        "ttoi = {}\n",
        "\n",
        "build_voc_w(stoi)\n",
        "build_voc_t(ttoi)\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "creator(x, y, stoi, ttoi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-kObblAdico"
      },
      "source": [
        "Пример данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvzEn9Czsmro",
        "outputId": "0dea1b38-708d-4614-d3c8-080eee857d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 0]]\n",
            "[0, 0, 1, 2, 0]\n"
          ]
        }
      ],
      "source": [
        "print(x[:5])\n",
        "print(y[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMAj5VdRdlN4"
      },
      "source": [
        "Определяем устройство на котором будет обучаться модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "owaWm1e7vFbn"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjOBJjH3gW1o"
      },
      "source": [
        "Переопределяем класс Dataset из torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9gFNFzvSQDlw"
      },
      "outputs": [],
      "source": [
        "class PosTagDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "        self.x = torch.LongTensor(self.x).to(device)\n",
        "        self.y = torch.LongTensor(self.y).to(device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.x[idx], self.y[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создаем функцию для разделения данных, указываем параметр stratify для сбалансированности классов"
      ],
      "metadata": {
        "id": "NwDSL3S3c9M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_test_split(x, y, train_size=0.7, val_size=0.1):\n",
        "    #test = 1 - train - val\n",
        "    x_train, x_, y_train, y_ = train_test_split(x, y, train_size=train_size, stratify=y, shuffle=True)\n",
        "    x_val, x_test, y_val, y_test = train_test_split(x_, y_, train_size=val_size/(1-train_size), stratify=y_, shuffle=True)\n",
        "\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test"
      ],
      "metadata": {
        "id": "xZKpWwGabfLl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8b__Uvqgd5_"
      },
      "source": [
        "Делим данные на три множества: train, validation, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VrMR9QCritJv"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_val, y_val, x_test, y_test = train_val_test_split(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMa0BAUdgx9w"
      },
      "source": [
        "Создаем датасеты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "tOAkG3wTb8EH"
      },
      "outputs": [],
      "source": [
        "dataset_train = PosTagDataset(x_train, y_train)\n",
        "dataset_val = PosTagDataset(x_val, y_val)\n",
        "dataset_test = PosTagDataset(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MxxpQhZhG3o"
      },
      "source": [
        "Проверяем корректность метода '__getitem __'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDCnpU0dtHFf",
        "outputId": "48a205ba-6047-4193-dd94-371ab0e3cc77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([814,  23,  10]), tensor(0))\n"
          ]
        }
      ],
      "source": [
        "print(dataset_train.__getitem__(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByFwdujyhpfZ"
      },
      "source": [
        "Создаем DataLoader на основе созданные ранее датасетов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PAskNf0JkRKP"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
        "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRHAaZK2hqhR"
      },
      "source": [
        "Определяем функцию для получения весов из W2V модели, чтобы в дальнейшем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1awTEQ1woAC1"
      },
      "outputs": [],
      "source": [
        "#перевод word2vec в массив весов для слоя Embedding    \n",
        "def make_e_weights():\n",
        "    # wv.index2word - список слов словаря\n",
        "    # wv.vectors - массив координат слов\n",
        "    dict_w2v = dict(zip(w2v_model.wv.index2word, w2v_model.wv.vectors))\n",
        "    e_weights = np.zeros((len(stoi), size))\n",
        "    for w, t in stoi.items(): # Слово и его код\n",
        "        w_coords = dict_w2v.get(w) # Координаты слова\n",
        "        if w_coords is not None:\n",
        "            e_weights[t] = w_coords\n",
        "    return torch.FloatTensor(e_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8dGqlvviLyB"
      },
      "source": [
        "Определяем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GOaU-d1fqitQ"
      },
      "outputs": [],
      "source": [
        "class W2VPoSTagger(nn.Module):\n",
        "    def __init__(self, size_w2v, hidden_layer_s):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        weights = make_e_weights()\n",
        "        weights.to(device)\n",
        "        self.embedding = nn.Embedding.from_pretrained(weights, freeze=False)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.fc1 = nn.Linear(size_w2v * 3, hidden_layer_s)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_layer_s, len(ttoi))\n",
        "        self.act2 = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc2(x)\n",
        "        #x = self.act2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao9luUGziPpQ"
      },
      "source": [
        "Создаем экземпляр модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQiUmrJp553C",
        "outputId": "2e74d229-3376-4e19-aebb-1a074acebe52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2VPoSTagger(\n",
            "  (embedding): Embedding(66179, 30)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=90, out_features=30, bias=True)\n",
            "  (act1): ReLU()\n",
            "  (fc2): Linear(in_features=30, out_features=22, bias=True)\n",
            "  (act2): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = W2VPoSTagger(size_w2v=size, hidden_layer_s=30)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpIF_htIiWDQ"
      },
      "source": [
        "Считаем количество параметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KK7dspH56RJ",
        "outputId": "dea14d47-9c09-4190-b704-3730da6b689e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель имеет 1,988,782 обучаемых параметров\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Модель имеет {count_parameters(model):,} обучаемых параметров')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZr65H7pjaGZ"
      },
      "source": [
        "# Часть 3. Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSLVhsRmi8C4"
      },
      "source": [
        "Определяем оптимизатор и функцию потерь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-LLsSvZg6Hnx"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJVEm-2pjRYZ"
      },
      "source": [
        "Помещаем модель и функцию потерь на `device`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "v9SAOm816LWa"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKu_n08ykDAq"
      },
      "source": [
        "Определяем функцию обучения модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "GHUIs3L66PUp"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    all_preds = []\n",
        "    all_tags = []\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        text = batch[0]\n",
        "        tags = batch[1]\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(text)\n",
        "\n",
        "        all_preds.append(predictions.detach().cpu().numpy())\n",
        "        all_tags.append(tags.detach().cpu().numpy())\n",
        "\n",
        "        loss = criterion(predictions, tags)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        \n",
        "    return epoch_loss / len(iterator), np.concatenate(all_preds, 0).argmax(1).reshape(-1), np.concatenate(all_tags, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDa6MrdCkIHx"
      },
      "source": [
        "Определяем функцию валидации модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Vm_3DZiX6TbJ"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_tags = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text = batch[0]\n",
        "            tags = batch[1]\n",
        "            \n",
        "            predictions = model(text)\n",
        "\n",
        "            all_preds.append(predictions.detach().cpu().numpy())\n",
        "            all_tags.append(tags.detach().cpu().numpy())\n",
        "            \n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), np.concatenate(all_preds, 0).argmax(1).reshape(-1), np.concatenate(all_tags, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqToCQgWkMzB"
      },
      "source": [
        "Определяем функцию для подсчета времени выполнения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "snT_IcJe6W-5"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhu1W_GEmEgo"
      },
      "source": [
        "Задаем параметры для `classification_report`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GasDGzLAZk_I",
        "outputId": "8780f959-8ac7-4972-c66f-dcc6f83a4446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
            "['NOUN', 'VERB', 'INFN', 'PRCL', 'PREP', 'ADJF', 'NPRO', 'ADVB', 'PRED', 'CONJ', 'Name', 'Surn', 'PRTF', 'COMP', 'NUMR', 'UNKN', 'Patr', 'INTJ', 'PRTS', 'GRND', 'Geox', 'ADJS']\n"
          ]
        }
      ],
      "source": [
        "cr_labels = []\n",
        "cr_names = []\n",
        "\n",
        "for name, label in ttoi.items():\n",
        "    cr_labels.append(label)\n",
        "    cr_names.append(name)\n",
        "\n",
        "print(cr_labels)\n",
        "print(cr_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIdF6trwmLPg"
      },
      "source": [
        "Обучаем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvO_nXHl6fBJ",
        "outputId": "342750ab-f449-403f-a57d-ad0921900f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 11m 57s\n",
            "\tTrain Loss: 0.546\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.88      0.93      0.90    356194\n",
            "        VERB       0.69      0.86      0.76     96780\n",
            "        INFN       0.69      0.46      0.55     25493\n",
            "        PRCL       0.88      0.85      0.87     32664\n",
            "        PREP       0.97      0.98      0.97    130292\n",
            "        ADJF       0.82      0.85      0.84    163014\n",
            "        NPRO       0.86      0.84      0.85     32607\n",
            "        ADVB       0.79      0.71      0.75     41082\n",
            "        PRED       0.85      0.67      0.75      3576\n",
            "        CONJ       0.92      0.95      0.94     96608\n",
            "        Name       0.62      0.51      0.56     12913\n",
            "        Surn       0.58      0.41      0.48      9474\n",
            "        PRTF       0.46      0.12      0.19     17090\n",
            "        COMP       0.60      0.27      0.37      2589\n",
            "        NUMR       0.87      0.76      0.81      5613\n",
            "        UNKN       0.48      0.38      0.43     23719\n",
            "        Patr       0.71      0.25      0.37       853\n",
            "        INTJ       0.74      0.37      0.49      1778\n",
            "        PRTS       0.56      0.29      0.38      7456\n",
            "        GRND       0.00      0.00      0.00      4983\n",
            "        Geox       0.83      0.67      0.74     15794\n",
            "        ADJS       0.55      0.25      0.34      8668\n",
            "\n",
            "    accuracy                           0.84   1089240\n",
            "   macro avg       0.70      0.56      0.61   1089240\n",
            "weighted avg       0.83      0.84      0.83   1089240\n",
            "\n",
            "\t Val Loss: 0.335\n",
            "Epoch: 02 | Epoch Time: 12m 7s\n",
            "\tTrain Loss: 0.370\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.94      0.95      0.94    356194\n",
            "        VERB       0.74      0.90      0.81     96780\n",
            "        INFN       0.76      0.54      0.63     25493\n",
            "        PRCL       0.93      0.91      0.92     32664\n",
            "        PREP       0.98      0.99      0.99    130292\n",
            "        ADJF       0.88      0.90      0.89    163014\n",
            "        NPRO       0.89      0.89      0.89     32607\n",
            "        ADVB       0.89      0.85      0.87     41082\n",
            "        PRED       0.89      0.81      0.85      3576\n",
            "        CONJ       0.97      0.98      0.97     96608\n",
            "        Name       0.75      0.64      0.69     12913\n",
            "        Surn       0.71      0.59      0.64      9474\n",
            "        PRTF       0.55      0.24      0.33     17090\n",
            "        COMP       0.69      0.49      0.57      2589\n",
            "        NUMR       0.92      0.91      0.92      5613\n",
            "        UNKN       0.51      0.59      0.55     23719\n",
            "        Patr       0.80      0.53      0.63       853\n",
            "        INTJ       0.80      0.68      0.74      1778\n",
            "        PRTS       0.60      0.45      0.51      7456\n",
            "        GRND       0.23      0.00      0.01      4983\n",
            "        Geox       0.89      0.80      0.84     15794\n",
            "        ADJS       0.64      0.42      0.51      8668\n",
            "\n",
            "    accuracy                           0.89   1089240\n",
            "   macro avg       0.77      0.68      0.71   1089240\n",
            "weighted avg       0.88      0.89      0.88   1089240\n",
            "\n",
            "\t Val Loss: 0.289\n",
            "Epoch: 03 | Epoch Time: 11m 48s\n",
            "\tTrain Loss: 0.317\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.96      0.96      0.96    356194\n",
            "        VERB       0.76      0.91      0.83     96780\n",
            "        INFN       0.78      0.55      0.65     25493\n",
            "        PRCL       0.93      0.91      0.92     32664\n",
            "        PREP       0.98      0.99      0.99    130292\n",
            "        ADJF       0.90      0.92      0.91    163014\n",
            "        NPRO       0.90      0.90      0.90     32607\n",
            "        ADVB       0.92      0.88      0.90     41082\n",
            "        PRED       0.90      0.83      0.86      3576\n",
            "        CONJ       0.97      0.98      0.98     96608\n",
            "        Name       0.81      0.70      0.75     12913\n",
            "        Surn       0.78      0.68      0.72      9474\n",
            "        PRTF       0.59      0.31      0.40     17090\n",
            "        COMP       0.73      0.55      0.63      2589\n",
            "        NUMR       0.93      0.93      0.93      5613\n",
            "        UNKN       0.55      0.67      0.61     23719\n",
            "        Patr       0.84      0.62      0.71       853\n",
            "        INTJ       0.81      0.71      0.76      1778\n",
            "        PRTS       0.63      0.51      0.56      7456\n",
            "        GRND       0.34      0.01      0.02      4983\n",
            "        Geox       0.91      0.84      0.88     15794\n",
            "        ADJS       0.67      0.47      0.56      8668\n",
            "\n",
            "    accuracy                           0.90   1089240\n",
            "   macro avg       0.80      0.72      0.75   1089240\n",
            "weighted avg       0.90      0.90      0.90   1089240\n",
            "\n",
            "\t Val Loss: 0.266\n",
            "Epoch: 04 | Epoch Time: 11m 56s\n",
            "\tTrain Loss: 0.284\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.97      0.97      0.97    356194\n",
            "        VERB       0.77      0.91      0.84     96780\n",
            "        INFN       0.79      0.57      0.66     25493\n",
            "        PRCL       0.94      0.92      0.93     32664\n",
            "        PREP       0.98      0.99      0.99    130292\n",
            "        ADJF       0.91      0.93      0.92    163014\n",
            "        NPRO       0.91      0.90      0.90     32607\n",
            "        ADVB       0.93      0.89      0.91     41082\n",
            "        PRED       0.91      0.84      0.88      3576\n",
            "        CONJ       0.97      0.98      0.98     96608\n",
            "        Name       0.86      0.74      0.79     12913\n",
            "        Surn       0.83      0.73      0.78      9474\n",
            "        PRTF       0.62      0.36      0.45     17090\n",
            "        COMP       0.74      0.58      0.65      2589\n",
            "        NUMR       0.94      0.94      0.94      5613\n",
            "        UNKN       0.61      0.74      0.67     23719\n",
            "        Patr       0.88      0.69      0.77       853\n",
            "        INTJ       0.81      0.73      0.77      1778\n",
            "        PRTS       0.66      0.54      0.59      7456\n",
            "        GRND       0.45      0.03      0.05      4983\n",
            "        Geox       0.93      0.87      0.90     15794\n",
            "        ADJS       0.69      0.52      0.59      8668\n",
            "\n",
            "    accuracy                           0.91   1089240\n",
            "   macro avg       0.82      0.74      0.77   1089240\n",
            "weighted avg       0.91      0.91      0.91   1089240\n",
            "\n",
            "\t Val Loss: 0.252\n",
            "Epoch: 05 | Epoch Time: 11m 41s\n",
            "\tTrain Loss: 0.261\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.97      0.97      0.97    356194\n",
            "        VERB       0.78      0.92      0.84     96780\n",
            "        INFN       0.80      0.58      0.67     25493\n",
            "        PRCL       0.94      0.92      0.93     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.92      0.94      0.93    163014\n",
            "        NPRO       0.91      0.90      0.91     32607\n",
            "        ADVB       0.94      0.91      0.92     41082\n",
            "        PRED       0.91      0.85      0.88      3576\n",
            "        CONJ       0.97      0.98      0.98     96608\n",
            "        Name       0.88      0.77      0.82     12913\n",
            "        Surn       0.86      0.77      0.81      9474\n",
            "        PRTF       0.64      0.39      0.48     17090\n",
            "        COMP       0.75      0.59      0.66      2589\n",
            "        NUMR       0.94      0.95      0.94      5613\n",
            "        UNKN       0.67      0.79      0.72     23719\n",
            "        Patr       0.88      0.73      0.80       853\n",
            "        INTJ       0.82      0.75      0.78      1778\n",
            "        PRTS       0.66      0.55      0.60      7456\n",
            "        GRND       0.44      0.03      0.06      4983\n",
            "        Geox       0.94      0.88      0.91     15794\n",
            "        ADJS       0.70      0.55      0.61      8668\n",
            "\n",
            "    accuracy                           0.92   1089240\n",
            "   macro avg       0.83      0.76      0.78   1089240\n",
            "weighted avg       0.92      0.92      0.92   1089240\n",
            "\n",
            "\t Val Loss: 0.241\n",
            "Epoch: 06 | Epoch Time: 11m 38s\n",
            "\tTrain Loss: 0.243\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.98      0.98      0.98    356194\n",
            "        VERB       0.78      0.92      0.85     96780\n",
            "        INFN       0.81      0.59      0.68     25493\n",
            "        PRCL       0.94      0.92      0.93     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.93      0.95      0.94    163014\n",
            "        NPRO       0.91      0.90      0.91     32607\n",
            "        ADVB       0.94      0.91      0.93     41082\n",
            "        PRED       0.91      0.85      0.88      3576\n",
            "        CONJ       0.97      0.98      0.98     96608\n",
            "        Name       0.89      0.79      0.84     12913\n",
            "        Surn       0.88      0.79      0.83      9474\n",
            "        PRTF       0.65      0.42      0.51     17090\n",
            "        COMP       0.77      0.61      0.68      2589\n",
            "        NUMR       0.94      0.95      0.95      5613\n",
            "        UNKN       0.72      0.83      0.77     23719\n",
            "        Patr       0.90      0.77      0.83       853\n",
            "        INTJ       0.83      0.76      0.79      1778\n",
            "        PRTS       0.69      0.57      0.63      7456\n",
            "        GRND       0.46      0.04      0.07      4983\n",
            "        Geox       0.95      0.89      0.92     15794\n",
            "        ADJS       0.71      0.56      0.63      8668\n",
            "\n",
            "    accuracy                           0.93   1089240\n",
            "   macro avg       0.84      0.77      0.80   1089240\n",
            "weighted avg       0.92      0.93      0.92   1089240\n",
            "\n",
            "\t Val Loss: 0.233\n",
            "Epoch: 07 | Epoch Time: 11m 49s\n",
            "\tTrain Loss: 0.229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.98      0.98      0.98    356194\n",
            "        VERB       0.79      0.93      0.85     96780\n",
            "        INFN       0.81      0.60      0.69     25493\n",
            "        PRCL       0.94      0.92      0.93     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.93      0.95      0.94    163014\n",
            "        NPRO       0.92      0.91      0.91     32607\n",
            "        ADVB       0.95      0.92      0.93     41082\n",
            "        PRED       0.92      0.85      0.88      3576\n",
            "        CONJ       0.97      0.98      0.98     96608\n",
            "        Name       0.91      0.80      0.85     12913\n",
            "        Surn       0.89      0.82      0.85      9474\n",
            "        PRTF       0.67      0.44      0.53     17090\n",
            "        COMP       0.76      0.62      0.68      2589\n",
            "        NUMR       0.95      0.95      0.95      5613\n",
            "        UNKN       0.77      0.86      0.81     23719\n",
            "        Patr       0.92      0.80      0.85       853\n",
            "        INTJ       0.82      0.78      0.80      1778\n",
            "        PRTS       0.69      0.59      0.64      7456\n",
            "        GRND       0.53      0.05      0.09      4983\n",
            "        Geox       0.95      0.90      0.93     15794\n",
            "        ADJS       0.72      0.58      0.64      8668\n",
            "\n",
            "    accuracy                           0.93   1089240\n",
            "   macro avg       0.85      0.78      0.81   1089240\n",
            "weighted avg       0.93      0.93      0.93   1089240\n",
            "\n",
            "\t Val Loss: 0.228\n",
            "Epoch: 08 | Epoch Time: 11m 43s\n",
            "\tTrain Loss: 0.219\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.98      0.98      0.98    356194\n",
            "        VERB       0.79      0.93      0.86     96780\n",
            "        INFN       0.82      0.61      0.70     25493\n",
            "        PRCL       0.94      0.93      0.93     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.94      0.96      0.95    163014\n",
            "        NPRO       0.92      0.91      0.91     32607\n",
            "        ADVB       0.95      0.92      0.94     41082\n",
            "        PRED       0.91      0.86      0.88      3576\n",
            "        CONJ       0.97      0.99      0.98     96608\n",
            "        Name       0.92      0.82      0.86     12913\n",
            "        Surn       0.90      0.83      0.87      9474\n",
            "        PRTF       0.67      0.46      0.55     17090\n",
            "        COMP       0.77      0.64      0.70      2589\n",
            "        NUMR       0.95      0.95      0.95      5613\n",
            "        UNKN       0.82      0.89      0.85     23719\n",
            "        Patr       0.92      0.81      0.86       853\n",
            "        INTJ       0.82      0.78      0.80      1778\n",
            "        PRTS       0.70      0.60      0.65      7456\n",
            "        GRND       0.50      0.05      0.09      4983\n",
            "        Geox       0.96      0.91      0.93     15794\n",
            "        ADJS       0.73      0.59      0.65      8668\n",
            "\n",
            "    accuracy                           0.93   1089240\n",
            "   macro avg       0.86      0.79      0.81   1089240\n",
            "weighted avg       0.93      0.93      0.93   1089240\n",
            "\n",
            "\t Val Loss: 0.224\n",
            "Epoch: 09 | Epoch Time: 11m 59s\n",
            "\tTrain Loss: 0.210\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.98      0.98      0.98    356194\n",
            "        VERB       0.80      0.93      0.86     96780\n",
            "        INFN       0.82      0.61      0.70     25493\n",
            "        PRCL       0.94      0.93      0.93     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.94      0.96      0.95    163014\n",
            "        NPRO       0.92      0.91      0.92     32607\n",
            "        ADVB       0.95      0.93      0.94     41082\n",
            "        PRED       0.92      0.86      0.89      3576\n",
            "        CONJ       0.98      0.98      0.98     96608\n",
            "        Name       0.92      0.83      0.87     12913\n",
            "        Surn       0.91      0.85      0.88      9474\n",
            "        PRTF       0.69      0.48      0.56     17090\n",
            "        COMP       0.77      0.64      0.70      2589\n",
            "        NUMR       0.94      0.95      0.95      5613\n",
            "        UNKN       0.85      0.90      0.87     23719\n",
            "        Patr       0.93      0.82      0.88       853\n",
            "        INTJ       0.82      0.79      0.81      1778\n",
            "        PRTS       0.71      0.61      0.65      7456\n",
            "        GRND       0.52      0.06      0.10      4983\n",
            "        Geox       0.96      0.91      0.94     15794\n",
            "        ADJS       0.73      0.61      0.66      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.86      0.80      0.82   1089240\n",
            "weighted avg       0.93      0.94      0.93   1089240\n",
            "\n",
            "\t Val Loss: 0.221\n",
            "Epoch: 10 | Epoch Time: 12m 6s\n",
            "\tTrain Loss: 0.203\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.98      0.98      0.98    356194\n",
            "        VERB       0.80      0.93      0.86     96780\n",
            "        INFN       0.82      0.62      0.70     25493\n",
            "        PRCL       0.94      0.93      0.94     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.94      0.96      0.95    163014\n",
            "        NPRO       0.92      0.91      0.92     32607\n",
            "        ADVB       0.95      0.93      0.94     41082\n",
            "        PRED       0.92      0.85      0.89      3576\n",
            "        CONJ       0.98      0.99      0.98     96608\n",
            "        Name       0.92      0.84      0.88     12913\n",
            "        Surn       0.92      0.86      0.89      9474\n",
            "        PRTF       0.69      0.49      0.57     17090\n",
            "        COMP       0.79      0.66      0.72      2589\n",
            "        NUMR       0.94      0.96      0.95      5613\n",
            "        UNKN       0.87      0.91      0.89     23719\n",
            "        Patr       0.92      0.83      0.87       853\n",
            "        INTJ       0.83      0.80      0.82      1778\n",
            "        PRTS       0.71      0.61      0.66      7456\n",
            "        GRND       0.51      0.06      0.10      4983\n",
            "        Geox       0.96      0.92      0.94     15794\n",
            "        ADJS       0.74      0.62      0.68      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.87      0.80      0.82   1089240\n",
            "weighted avg       0.94      0.94      0.94   1089240\n",
            "\n",
            "\t Val Loss: 0.219\n",
            "Epoch: 11 | Epoch Time: 11m 47s\n",
            "\tTrain Loss: 0.197\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.99      0.98      0.99    356194\n",
            "        VERB       0.80      0.93      0.86     96780\n",
            "        INFN       0.82      0.62      0.71     25493\n",
            "        PRCL       0.94      0.93      0.93     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.94      0.96      0.95    163014\n",
            "        NPRO       0.92      0.91      0.92     32607\n",
            "        ADVB       0.95      0.93      0.94     41082\n",
            "        PRED       0.92      0.85      0.88      3576\n",
            "        CONJ       0.98      0.99      0.98     96608\n",
            "        Name       0.93      0.85      0.89     12913\n",
            "        Surn       0.93      0.87      0.90      9474\n",
            "        PRTF       0.70      0.50      0.58     17090\n",
            "        COMP       0.79      0.66      0.72      2589\n",
            "        NUMR       0.94      0.96      0.95      5613\n",
            "        UNKN       0.89      0.92      0.90     23719\n",
            "        Patr       0.93      0.84      0.88       853\n",
            "        INTJ       0.83      0.80      0.82      1778\n",
            "        PRTS       0.72      0.62      0.67      7456\n",
            "        GRND       0.52      0.06      0.11      4983\n",
            "        Geox       0.96      0.92      0.94     15794\n",
            "        ADJS       0.74      0.62      0.68      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.87      0.81      0.83   1089240\n",
            "weighted avg       0.94      0.94      0.94   1089240\n",
            "\n",
            "\t Val Loss: 0.216\n",
            "Epoch: 12 | Epoch Time: 12m 11s\n",
            "\tTrain Loss: 0.192\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.99      0.99      0.99    356194\n",
            "        VERB       0.80      0.93      0.86     96780\n",
            "        INFN       0.82      0.62      0.71     25493\n",
            "        PRCL       0.94      0.93      0.94     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.94      0.96      0.95    163014\n",
            "        NPRO       0.92      0.91      0.92     32607\n",
            "        ADVB       0.95      0.94      0.95     41082\n",
            "        PRED       0.92      0.86      0.89      3576\n",
            "        CONJ       0.98      0.99      0.98     96608\n",
            "        Name       0.93      0.86      0.89     12913\n",
            "        Surn       0.93      0.88      0.90      9474\n",
            "        PRTF       0.70      0.51      0.59     17090\n",
            "        COMP       0.79      0.67      0.72      2589\n",
            "        NUMR       0.95      0.96      0.95      5613\n",
            "        UNKN       0.90      0.93      0.92     23719\n",
            "        Patr       0.93      0.85      0.89       853\n",
            "        INTJ       0.83      0.81      0.82      1778\n",
            "        PRTS       0.72      0.63      0.67      7456\n",
            "        GRND       0.55      0.07      0.13      4983\n",
            "        Geox       0.97      0.93      0.95     15794\n",
            "        ADJS       0.75      0.64      0.69      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.87      0.81      0.83   1089240\n",
            "weighted avg       0.94      0.94      0.94   1089240\n",
            "\n",
            "\t Val Loss: 0.215\n",
            "Epoch: 13 | Epoch Time: 11m 54s\n",
            "\tTrain Loss: 0.187\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.99      0.99      0.99    356194\n",
            "        VERB       0.81      0.94      0.87     96780\n",
            "        INFN       0.83      0.63      0.71     25493\n",
            "        PRCL       0.94      0.93      0.94     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.95      0.97      0.96    163014\n",
            "        NPRO       0.93      0.92      0.92     32607\n",
            "        ADVB       0.96      0.94      0.95     41082\n",
            "        PRED       0.91      0.85      0.88      3576\n",
            "        CONJ       0.98      0.99      0.98     96608\n",
            "        Name       0.93      0.86      0.89     12913\n",
            "        Surn       0.93      0.89      0.91      9474\n",
            "        PRTF       0.71      0.52      0.60     17090\n",
            "        COMP       0.79      0.67      0.72      2589\n",
            "        NUMR       0.95      0.96      0.95      5613\n",
            "        UNKN       0.92      0.93      0.92     23719\n",
            "        Patr       0.94      0.86      0.90       853\n",
            "        INTJ       0.84      0.82      0.83      1778\n",
            "        PRTS       0.73      0.64      0.68      7456\n",
            "        GRND       0.53      0.08      0.13      4983\n",
            "        Geox       0.97      0.93      0.95     15794\n",
            "        ADJS       0.75      0.65      0.69      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.87      0.82      0.83   1089240\n",
            "weighted avg       0.94      0.94      0.94   1089240\n",
            "\n",
            "\t Val Loss: 0.214\n",
            "Epoch: 14 | Epoch Time: 11m 45s\n",
            "\tTrain Loss: 0.184\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.99      0.99      0.99    356194\n",
            "        VERB       0.81      0.94      0.87     96780\n",
            "        INFN       0.83      0.63      0.72     25493\n",
            "        PRCL       0.94      0.93      0.94     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.95      0.97      0.96    163014\n",
            "        NPRO       0.93      0.92      0.92     32607\n",
            "        ADVB       0.96      0.94      0.95     41082\n",
            "        PRED       0.92      0.86      0.89      3576\n",
            "        CONJ       0.98      0.99      0.98     96608\n",
            "        Name       0.93      0.86      0.90     12913\n",
            "        Surn       0.94      0.90      0.92      9474\n",
            "        PRTF       0.71      0.53      0.61     17090\n",
            "        COMP       0.79      0.67      0.73      2589\n",
            "        NUMR       0.95      0.96      0.96      5613\n",
            "        UNKN       0.93      0.94      0.93     23719\n",
            "        Patr       0.94      0.86      0.90       853\n",
            "        INTJ       0.83      0.83      0.83      1778\n",
            "        PRTS       0.72      0.63      0.67      7456\n",
            "        GRND       0.55      0.09      0.15      4983\n",
            "        Geox       0.97      0.94      0.95     15794\n",
            "        ADJS       0.75      0.65      0.70      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.88      0.82      0.84   1089240\n",
            "weighted avg       0.94      0.94      0.94   1089240\n",
            "\n",
            "\t Val Loss: 0.213\n",
            "Epoch: 15 | Epoch Time: 12m 4s\n",
            "\tTrain Loss: 0.181\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.99      0.99      0.99    356194\n",
            "        VERB       0.81      0.94      0.87     96780\n",
            "        INFN       0.83      0.63      0.72     25493\n",
            "        PRCL       0.94      0.93      0.94     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.95      0.97      0.96    163014\n",
            "        NPRO       0.93      0.92      0.92     32607\n",
            "        ADVB       0.96      0.94      0.95     41082\n",
            "        PRED       0.92      0.86      0.89      3576\n",
            "        CONJ       0.98      0.99      0.98     96608\n",
            "        Name       0.93      0.87      0.90     12913\n",
            "        Surn       0.94      0.91      0.92      9474\n",
            "        PRTF       0.72      0.54      0.62     17090\n",
            "        COMP       0.79      0.67      0.73      2589\n",
            "        NUMR       0.95      0.96      0.96      5613\n",
            "        UNKN       0.93      0.94      0.94     23719\n",
            "        Patr       0.95      0.86      0.91       853\n",
            "        INTJ       0.84      0.84      0.84      1778\n",
            "        PRTS       0.74      0.65      0.69      7456\n",
            "        GRND       0.56      0.09      0.16      4983\n",
            "        Geox       0.97      0.94      0.95     15794\n",
            "        ADJS       0.76      0.65      0.70      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.88      0.82      0.84   1089240\n",
            "weighted avg       0.94      0.94      0.94   1089240\n",
            "\n",
            "\t Val Loss: 0.211\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 15\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_preds, train_tags = train(model, dataloader_train, optimizer, criterion)\n",
        "    valid_loss, _, __ = evaluate(model, dataloader_val, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "\n",
        "    print(classification_report(train_tags, train_preds, labels=cr_labels, target_names=cr_names))\n",
        "\n",
        "    print(f'\\t Val Loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru-b_srcmoiJ"
      },
      "source": [
        "Тестируем модель на отложенной выборке"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZlL44226iiA",
        "outputId": "d872eff7-7ce2-4a21-b30c-81541eadf28d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.209\n",
            "[ 5 18 15 ...  0  0  5]\n",
            "[ 5 18 15 ...  0  0  5]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.98      0.97      0.98    101770\n",
            "        VERB       0.78      0.94      0.85     27652\n",
            "        INFN       0.87      0.60      0.71      7284\n",
            "        PRCL       0.95      0.94      0.94      9333\n",
            "        PREP       0.99      1.00      0.99     37226\n",
            "        ADJF       0.94      0.96      0.95     46575\n",
            "        NPRO       0.94      0.92      0.93      9316\n",
            "        ADVB       0.96      0.93      0.95     11738\n",
            "        PRED       0.92      0.88      0.90      1022\n",
            "        CONJ       0.98      0.99      0.98     27602\n",
            "        Name       0.91      0.86      0.88      3689\n",
            "        Surn       0.95      0.86      0.90      2707\n",
            "        PRTF       0.71      0.47      0.56      4883\n",
            "        COMP       0.73      0.76      0.75       739\n",
            "        NUMR       0.95      0.99      0.97      1603\n",
            "        UNKN       0.73      0.77      0.75      6777\n",
            "        Patr       0.94      0.92      0.93       243\n",
            "        INTJ       0.82      0.91      0.86       508\n",
            "        PRTS       0.69      0.65      0.67      2131\n",
            "        GRND       0.76      0.05      0.09      1424\n",
            "        Geox       0.96      0.93      0.94      4513\n",
            "        ADJS       0.75      0.65      0.69      2477\n",
            "\n",
            "    accuracy                           0.93    311212\n",
            "   macro avg       0.87      0.81      0.83    311212\n",
            "weighted avg       0.93      0.93      0.93    311212\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_preds, test_tags = evaluate(model, dataloader_test, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f}')\n",
        "\n",
        "print(test_preds[10:])\n",
        "print(test_tags[10:])\n",
        "\n",
        "print(classification_report(test_tags, test_preds, labels=cr_labels, target_names=cr_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYlsiBEXoWRJ"
      },
      "source": [
        "# Часть 4. Использование модели keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUVFr34LofQR"
      },
      "source": [
        "Импортируем необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "BxAn3VhawXcN"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import losses\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, Embedding, Dropout, Reshape\n",
        "import time\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.math import argmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwbm-rp9zaCN",
        "outputId": "49fc4f38-039f-4c51-d27d-704960356fbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 0], [0, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11]]\n",
            "[0, 0, 1, 2, 0, 1, 3, 0, 0, 4]\n"
          ]
        }
      ],
      "source": [
        "print(x[:10])\n",
        "print(y[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKVwKzFQp8II"
      },
      "source": [
        "Создаем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "AI7kIMuswi9t"
      },
      "outputs": [],
      "source": [
        "#создание модели          \n",
        "def create_model(sq, num_words, size, num_classes):\n",
        "    inp = Input(shape = (sq, ), dtype = 'int32')\n",
        "    e_weights = make_e_weights()\n",
        "    x = Embedding(num_words, output_dim = size, input_length = sq, \n",
        "                weights = [e_weights], trainable = True)(inp)\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(size, activation = 'relu', use_bias = True)(x)\n",
        "    output = Dense(num_classes, activation = 'softmax', use_bias = True)(x)\n",
        "    model = Model(inp, output)\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eaB_-hHp-Ow"
      },
      "source": [
        "Определяем функцию-обертку для `clasification_report`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Metrics(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.data = []\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        print(self.validation_data)\n",
        "        X_val, y_val = self.batch[0], self.batch[1]\n",
        "        y_predict = model.predict(X_val)\n",
        "\n",
        "        y_predict = argmax(y_predict, 1)\n",
        "\n",
        "        self.data.append(classification_report(y_val.numpy(), y_predict.numpy(), labels=cr_labels, target_names=cr_names))\n",
        "\n",
        "    def get_data(self):\n",
        "        return self.data"
      ],
      "metadata": {
        "id": "EQoR4uwSqvZH"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-OC6ykJqEhx"
      },
      "source": [
        "Обучаем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6lGdb2Xwpxl",
        "outputId": "f202098a-2532-449d-ab9f-aa27fd251d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3)]               0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 3, 30)             1985370   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 90)                0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 90)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 30)                2730      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 22)                682       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,988,782\n",
            "Trainable params: 1,988,782\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "9118/9118 - 463s - loss: 0.6150 - accuracy: 0.8208 - val_loss: 0.3486 - val_accuracy: 0.8949 - 463s/epoch - 51ms/step\n",
            "Epoch 2/15\n",
            "9118/9118 - 485s - loss: 0.3891 - accuracy: 0.8825 - val_loss: 0.2930 - val_accuracy: 0.9087 - 485s/epoch - 53ms/step\n",
            "Epoch 3/15\n",
            "9118/9118 - 458s - loss: 0.3295 - accuracy: 0.8994 - val_loss: 0.2664 - val_accuracy: 0.9170 - 458s/epoch - 50ms/step\n",
            "Epoch 4/15\n",
            "9118/9118 - 472s - loss: 0.2931 - accuracy: 0.9102 - val_loss: 0.2476 - val_accuracy: 0.9224 - 472s/epoch - 52ms/step\n",
            "Epoch 5/15\n",
            "9118/9118 - 451s - loss: 0.2681 - accuracy: 0.9183 - val_loss: 0.2373 - val_accuracy: 0.9250 - 451s/epoch - 49ms/step\n",
            "Epoch 6/15\n",
            "9118/9118 - 456s - loss: 0.2481 - accuracy: 0.9245 - val_loss: 0.2308 - val_accuracy: 0.9274 - 456s/epoch - 50ms/step\n",
            "Epoch 7/15\n",
            "9118/9118 - 468s - loss: 0.2330 - accuracy: 0.9295 - val_loss: 0.2236 - val_accuracy: 0.9295 - 468s/epoch - 51ms/step\n",
            "Epoch 8/15\n",
            "9118/9118 - 479s - loss: 0.2204 - accuracy: 0.9333 - val_loss: 0.2186 - val_accuracy: 0.9311 - 479s/epoch - 53ms/step\n",
            "Epoch 9/15\n",
            "9118/9118 - 488s - loss: 0.2107 - accuracy: 0.9358 - val_loss: 0.2149 - val_accuracy: 0.9325 - 488s/epoch - 54ms/step\n",
            "Epoch 10/15\n",
            "9118/9118 - 476s - loss: 0.2027 - accuracy: 0.9381 - val_loss: 0.2102 - val_accuracy: 0.9337 - 476s/epoch - 52ms/step\n",
            "Epoch 11/15\n",
            "9118/9118 - 475s - loss: 0.1958 - accuracy: 0.9399 - val_loss: 0.2093 - val_accuracy: 0.9339 - 475s/epoch - 52ms/step\n",
            "Epoch 12/15\n",
            "9118/9118 - 470s - loss: 0.1906 - accuracy: 0.9414 - val_loss: 0.2087 - val_accuracy: 0.9340 - 470s/epoch - 52ms/step\n",
            "Epoch 13/15\n",
            "9118/9118 - 492s - loss: 0.1860 - accuracy: 0.9427 - val_loss: 0.2075 - val_accuracy: 0.9346 - 492s/epoch - 54ms/step\n",
            "Epoch 14/15\n",
            "9118/9118 - 481s - loss: 0.1816 - accuracy: 0.9438 - val_loss: 0.2045 - val_accuracy: 0.9351 - 481s/epoch - 53ms/step\n",
            "Epoch 15/15\n",
            "9118/9118 - 496s - loss: 0.1775 - accuracy: 0.9450 - val_loss: 0.2045 - val_accuracy: 0.9354 - 496s/epoch - 54ms/step\n",
            "Full time: 7420.234338760376\n",
            "12157/12157 - 38s - 38s/epoch - 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.98      0.98      0.98    126991\n",
            "        VERB       0.80      0.93      0.86     34569\n",
            "        INFN       0.86      0.61      0.71      9128\n",
            "        PRCL       0.94      0.95      0.94     11586\n",
            "        PREP       0.98      1.00      0.99     46370\n",
            "        ADJF       0.93      0.96      0.95     58309\n",
            "        NPRO       0.94      0.91      0.92     11631\n",
            "        ADVB       0.96      0.94      0.95     14721\n",
            "        PRED       0.95      0.86      0.90      1206\n",
            "        CONJ       0.98      0.99      0.98     34600\n",
            "        Name       0.94      0.85      0.89      4660\n",
            "        Surn       0.94      0.87      0.90      3344\n",
            "        PRTF       0.64      0.55      0.59      6204\n",
            "        COMP       0.81      0.72      0.76       902\n",
            "        NUMR       0.95      0.98      0.97      2003\n",
            "        UNKN       0.75      0.77      0.76      8551\n",
            "        Patr       0.88      0.89      0.88       297\n",
            "        INTJ       0.87      0.90      0.89       655\n",
            "        PRTS       0.77      0.63      0.70      2658\n",
            "        GRND       0.60      0.07      0.12      1846\n",
            "        Geox       0.95      0.93      0.94      5660\n",
            "        ADJS       0.78      0.64      0.70      3124\n",
            "\n",
            "    accuracy                           0.94    389015\n",
            "   macro avg       0.87      0.81      0.83    389015\n",
            "weighted avg       0.93      0.94      0.93    389015\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#обучение НС\n",
        "model = create_model(3, len(stoi), 30, len(ttoi))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'], run_eagerly=True)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n",
        "\n",
        "startTime = time.time()\n",
        "metrics = Metrics()\n",
        "history = model.fit(x_train, y_train, batch_size = 128, epochs = 15, verbose = 2, validation_data = (x_test, y_test))\n",
        "print('Full time:', time.time() - startTime)\n",
        "\n",
        "pred = model.predict(x_test, batch_size=32, verbose=2)\n",
        "predicted = np.argmax(pred, axis=1)\n",
        "report = classification_report(y_test, predicted, labels=cr_labels, target_names=cr_names)\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "src_w2v.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
