{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe6Cs8n4uKRQ",
        "outputId": "a945d1da-b062-44e6-d690-88d3e2f4f8bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymorphy2[fast] in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.7.2)\n",
            "Requirement already satisfied: DAWG>=0.8 in /usr/local/lib/python3.7/dist-packages (from pymorphy2[fast]) (0.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pymorphy2[fast]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzL9GPKra1Nw"
      },
      "source": [
        "Импортируем библоитеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OWwej54saLSE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from nltk.stem.snowball import RussianStemmer\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLLLiXUQa5eA"
      },
      "source": [
        "#Часть 1. Чтение данных и первичная предобработка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9HsHUFMbFQQ"
      },
      "source": [
        "В программе будет три режима работы:\n",
        "1.   Без уменьшения словаря\n",
        "2.   Стемминг\n",
        "3.   Лемматизация\n",
	"4.   SentencePiece\n",
	"5.   BERTTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KJe5ClYi7Kr9"
      },
      "outputs": [],
      "source": [
        "REDUCTION_MODE = 2 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR3-c3Vebjzw"
      },
      "source": [
        "Подключаем гугл диск, где содержится файл с корпусом, который был получен ранее"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WULuCwwH9LJs",
        "outputId": "80773423-e7ae-4342-99c0-e754523f26ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive/')\n",
        "\n",
        "dir = 'drive/MyDrive/BS/DATA_EXTRACTION/'\n",
        "corp_cased = dir + 'corp_cased.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F03tQFjbznw"
      },
      "source": [
        "Считываем csv файл корпуса и выводим первые пять элементов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AOIpuBdx9TU0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "818cc977-2ef2-4501-b5b9-83ade17942bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0  \\\n",
              "0                Школа злословия учит прикусить язык   \n",
              "1      Сохранится ли градус дискуссии в новом сезоне   \n",
              "2  Великолепная Школа злословия вернулась в эфир ...   \n",
              "3   В истории программы это уже не первый ребрендинг   \n",
              "4  Сейчас с трудом можно припомнить что начиналас...   \n",
              "\n",
              "                                                   1  \n",
              "0                           NOUN NOUN VERB INFN NOUN  \n",
              "1                 VERB PRCL NOUN NOUN PREP ADJF NOUN  \n",
              "2  ADJF NOUN NOUN VERB PREP NOUN PREP ADJF NOUN P...  \n",
              "3            PREP NOUN NOUN NPRO ADVB PRCL ADJF NOUN  \n",
              "4  ADVB PREP NOUN PRED INFN CONJ VERB NOUN PREP N...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8636630e-ca73-4790-a9c3-752add9ed2fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Школа злословия учит прикусить язык</td>\n",
              "      <td>NOUN NOUN VERB INFN NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Сохранится ли градус дискуссии в новом сезоне</td>\n",
              "      <td>VERB PRCL NOUN NOUN PREP ADJF NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Великолепная Школа злословия вернулась в эфир ...</td>\n",
              "      <td>ADJF NOUN NOUN VERB PREP NOUN PREP ADJF NOUN P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>В истории программы это уже не первый ребрендинг</td>\n",
              "      <td>PREP NOUN NOUN NPRO ADVB PRCL ADJF NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Сейчас с трудом можно припомнить что начиналас...</td>\n",
              "      <td>ADVB PREP NOUN PRED INFN CONJ VERB NOUN PREP N...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8636630e-ca73-4790-a9c3-752add9ed2fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8636630e-ca73-4790-a9c3-752add9ed2fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8636630e-ca73-4790-a9c3-752add9ed2fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv(corp_cased, sep='\\t', header=None, on_bad_lines='skip')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKUJIAF-EmFe"
      },
      "source": [
        "Удаялем строки с nan значениями"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x6x_OmcRDyr1"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EOHrtjQdGzFb"
      },
      "outputs": [],
      "source": [
        "stemmer = RussianStemmer()\n",
        "lemmatizer = MorphAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7kr_wTOb-7Y"
      },
      "source": [
        "Определяем функцию, которая исходя из режима работы делает соотвестующие преобразования слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lzLqDhbz_TI-"
      },
      "outputs": [],
      "source": [
        "def reduction(x):\n",
        "    x = str(x)\n",
        "    if REDUCTION_MODE == 0:\n",
        "        return x.split()\n",
        "    elif REDUCTION_MODE == 1:\n",
        "        return [stemmer.stem(token) for token in x.split(' ')]\n",
        "    elif REDUCTION_MODE == 2:\n",
        "        return [lemmatizer.normal_forms(token)[0] for token in x.split(' ')]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRPa8OUScGyI"
      },
      "source": [
        "Используем функцию выше"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_full_measure = time.perf_counter()"
      ],
      "metadata": {
        "id": "JSZNCwLEIJpX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H1teZPfiNQLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d54545-fdb4-4073-e067-1fd62aa2bb79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[list(['школа', 'злословие', 'учить', 'прикусить', 'язык'])\n",
            " list(['сохраниться', 'ли', 'градус', 'дискуссия', 'в', 'новый', 'сезон'])\n",
            " list(['великолепный', 'школа', 'злословие', 'вернуться', 'в', 'эфир', 'после', 'летний', 'каникулы', 'в', 'новый', 'формат'])\n",
            " list(['в', 'история', 'программа', 'это', 'уже', 'не', 'первый', 'ребрендинг'])\n",
            " list(['сейчас', 'с', 'труд', 'можно', 'припомнить', 'что', 'начинаться', 'школа', 'на', 'канал', 'культура', 'как', 'стандартный', 'ток-шоу', 'который', 'отличаться', 'от', 'другой', 'кухонный', 'обсуждение', 'гость', 'что', 'называться', 'за', 'глаз', 'и', 'неожиданный', 'персона', 'в', 'качество', 'ведущий'])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "sentences = df[0].to_numpy()\n",
        "\n",
        "sentences = np.array(list(map(reduction, sentences)))\n",
        "\n",
        "print(sentences[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSsnmhUIcKOA"
      },
      "source": [
        "Также разделяем теги на токены"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_rp79vyIXEGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb43af6-ca1a-4258-a095-429ed5748a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[list(['NOUN', 'NOUN', 'VERB', 'INFN', 'NOUN'])\n",
            " list(['VERB', 'PRCL', 'NOUN', 'NOUN', 'PREP', 'ADJF', 'NOUN'])\n",
            " list(['ADJF', 'NOUN', 'NOUN', 'VERB', 'PREP', 'NOUN', 'PREP', 'ADJF', 'NOUN', 'PREP', 'ADJF', 'NOUN'])\n",
            " list(['PREP', 'NOUN', 'NOUN', 'NPRO', 'ADVB', 'PRCL', 'ADJF', 'NOUN'])\n",
            " list(['ADVB', 'PREP', 'NOUN', 'PRED', 'INFN', 'CONJ', 'VERB', 'NOUN', 'PREP', 'NOUN', 'NOUN', 'CONJ', 'ADJF', 'NOUN', 'ADJF', 'VERB', 'PREP', 'ADJF', 'ADJF', 'NOUN', 'NOUN', 'CONJ', 'VERB', 'PREP', 'NOUN', 'CONJ', 'ADJF', 'NOUN', 'PREP', 'NOUN', 'ADJF'])]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ],
      "source": [
        "tags = df[1].to_numpy()\n",
        "\n",
        "tags = np.array(list(map(lambda x: str(x).split(), tags)))\n",
        "\n",
        "print(tags[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cpEeNgUcolg"
      },
      "source": [
        "Создаем Word2Vec модель из имеющихся предложений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "P8_ypRR3XFGD"
      },
      "outputs": [],
      "source": [
        "size, window, min_cnt, sg = 30, 2, 2, 0 # Используем модель CBOW\n",
        "workers = multiprocessing.cpu_count()\n",
        "n_iter = 150\n",
        "w2v_model = Word2Vec(sentences, size = size, window = window, min_count = min_cnt,\n",
        "                    sg = sg, workers = workers, iter = n_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty1kBtgHczZ4"
      },
      "source": [
        "# Часть 2. Подготовка датасетов для моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn9FkzRhc5eo"
      },
      "source": [
        "Создаем функции для создания словарей слов и тегов (чтобы перевести текст в цифру), а также создаем модель для классификатора\\\n",
        "[слово_до, слово, слово_после] -> часть речи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "b8I53BK-iICH"
      },
      "outputs": [],
      "source": [
        "def build_voc_w(stoi):\n",
        "    idx = 1\n",
        "\n",
        "    for sentence in sentences:\n",
        "        for word in sentence:\n",
        "            if word not in stoi:\n",
        "                stoi[word] = idx\n",
        "                idx += 1\n",
        "\n",
        "\n",
        "def build_voc_t(ttoi):\n",
        "    idx = 0\n",
        "    \n",
        "    for tags_ in tags:\n",
        "        for tag in tags_:\n",
        "            if tag not in ttoi:\n",
        "                ttoi[tag] = idx\n",
        "                idx += 1\n",
        "\n",
        "def creator(x, y, stoi, ttoi):\n",
        "    for i in range(len(sentences)):\n",
        "        for j in range(len(sentences[i])):\n",
        "            x_elem = []\n",
        "            #word before\n",
        "            if j == 0:\n",
        "                x_elem.append(0)\n",
        "            else:\n",
        "                x_elem.append(stoi[sentences[i][j - 1]])\n",
        "\n",
        "            #current word\n",
        "            x_elem.append(stoi[sentences[i][j]])\n",
        "\n",
        "            #word after\n",
        "            if j == len(sentences[i]) - 1:\n",
        "                x_elem.append(0)\n",
        "            else:\n",
        "                x_elem.append(stoi[sentences[i][j + 1]])\n",
        "\n",
        "            x.append(x_elem)\n",
        "            y.append(ttoi[tags[i][j]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K9kuWSmdUuo"
      },
      "source": [
        "Применяем определенные выше функции. Нулевой индекс оставляем для выравнивания"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BTPKhFrviVUX"
      },
      "outputs": [],
      "source": [
        "#sentences vocs\n",
        "stoi = {None: 0}\n",
        "\n",
        "#tags vocs\n",
        "ttoi = {}\n",
        "\n",
        "build_voc_w(stoi)\n",
        "build_voc_t(ttoi)\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "creator(x, y, stoi, ttoi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-kObblAdico"
      },
      "source": [
        "Пример данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NvzEn9Czsmro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5876ad19-dc77-4c29-8b15-f776b2f7ab52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 0]]\n",
            "[0, 0, 1, 2, 0]\n"
          ]
        }
      ],
      "source": [
        "print(x[:5])\n",
        "print(y[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMAj5VdRdlN4"
      },
      "source": [
        "Определяем устройство на котором будет обучаться модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "owaWm1e7vFbn"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjOBJjH3gW1o"
      },
      "source": [
        "Переопределяем класс Dataset из torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9gFNFzvSQDlw"
      },
      "outputs": [],
      "source": [
        "class PosTagDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "        self.x = torch.LongTensor(self.x).to(device)\n",
        "        self.y = torch.LongTensor(self.y).to(device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.x[idx], self.y[idx])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwDSL3S3c9M0"
      },
      "source": [
        "Создаем функцию для разделения данных, указываем параметр stratify для сбалансированности классов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xZKpWwGabfLl"
      },
      "outputs": [],
      "source": [
        "def train_val_test_split(x, y, train_size=0.7, val_size=0.1):\n",
        "    #test = 1 - train - val\n",
        "    x_train, x_, y_train, y_ = train_test_split(x, y, train_size=train_size, stratify=y, shuffle=True)\n",
        "    x_val, x_test, y_val, y_test = train_test_split(x_, y_, train_size=val_size/(1-train_size), stratify=y_, shuffle=True)\n",
        "\n",
        "    return x_train, y_train, x_val, y_val, x_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8b__Uvqgd5_"
      },
      "source": [
        "Делим данные на три множества: train, validation, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "VrMR9QCritJv"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_val, y_val, x_test, y_test = train_val_test_split(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMa0BAUdgx9w"
      },
      "source": [
        "Создаем датасеты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tOAkG3wTb8EH"
      },
      "outputs": [],
      "source": [
        "dataset_train = PosTagDataset(x_train, y_train)\n",
        "dataset_val = PosTagDataset(x_val, y_val)\n",
        "dataset_test = PosTagDataset(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MxxpQhZhG3o"
      },
      "source": [
        "Проверяем корректность метода '__getitem __'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zDCnpU0dtHFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e3be6e-e980-4b96-9c52-8558bb1902da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([   0,   37, 1558], device='cuda:0'), tensor(9, device='cuda:0'))\n"
          ]
        }
      ],
      "source": [
        "print(dataset_train.__getitem__(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByFwdujyhpfZ"
      },
      "source": [
        "Создаем DataLoader на основе созданные ранее датасетов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PAskNf0JkRKP"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
        "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=False)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRHAaZK2hqhR"
      },
      "source": [
        "Определяем функцию для получения весов из W2V модели, чтобы в дальнейшем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1awTEQ1woAC1"
      },
      "outputs": [],
      "source": [
        "#перевод word2vec в массив весов для слоя Embedding    \n",
        "def make_e_weights():\n",
        "    # wv.index2word - список слов словаря\n",
        "    # wv.vectors - массив координат слов\n",
        "    dict_w2v = dict(zip(w2v_model.wv.index2word, w2v_model.wv.vectors))\n",
        "    e_weights = np.zeros((len(stoi), size))\n",
        "    for w, t in stoi.items(): # Слово и его код\n",
        "        w_coords = dict_w2v.get(w) # Координаты слова\n",
        "        if w_coords is not None:\n",
        "            e_weights[t] = w_coords\n",
        "    return torch.FloatTensor(e_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8dGqlvviLyB"
      },
      "source": [
        "Определяем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GOaU-d1fqitQ"
      },
      "outputs": [],
      "source": [
        "class W2VPoSTagger(nn.Module):\n",
        "    def __init__(self, size_w2v, hidden_layer_s):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        weights = make_e_weights()\n",
        "        weights.to(device)\n",
        "        self.embedding = nn.Embedding.from_pretrained(weights, freeze=False)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.fc1 = nn.Linear(size_w2v * 3, hidden_layer_s)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_layer_s, len(ttoi))\n",
        "        self.act2 = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc2(x)\n",
        "        #x = self.act2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao9luUGziPpQ"
      },
      "source": [
        "Создаем экземпляр модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XQiUmrJp553C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9480afa3-a4c4-47b8-ab28-703c720d8073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W2VPoSTagger(\n",
            "  (embedding): Embedding(66179, 30)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc1): Linear(in_features=90, out_features=30, bias=True)\n",
            "  (act1): ReLU()\n",
            "  (fc2): Linear(in_features=30, out_features=22, bias=True)\n",
            "  (act2): Softmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = W2VPoSTagger(size_w2v=size, hidden_layer_s=30)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpIF_htIiWDQ"
      },
      "source": [
        "Считаем количество параметров"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0KK7dspH56RJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1106d338-a6b9-48e5-ff71-058321726519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель имеет 1,988,782 обучаемых параметров\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'Модель имеет {count_parameters(model):,} обучаемых параметров')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZr65H7pjaGZ"
      },
      "source": [
        "# Часть 3. Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSLVhsRmi8C4"
      },
      "source": [
        "Определяем оптимизатор и функцию потерь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-LLsSvZg6Hnx"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJVEm-2pjRYZ"
      },
      "source": [
        "Помещаем модель и функцию потерь на `device`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "v9SAOm816LWa"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKu_n08ykDAq"
      },
      "source": [
        "Определяем функцию обучения модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "GHUIs3L66PUp"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    all_preds = []\n",
        "    all_tags = []\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        text = batch[0]\n",
        "        tags = batch[1]\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(text)\n",
        "\n",
        "        all_preds.append(predictions.detach().cpu().numpy())\n",
        "        all_tags.append(tags.detach().cpu().numpy())\n",
        "\n",
        "        loss = criterion(predictions, tags)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        \n",
        "    return epoch_loss / len(iterator), np.concatenate(all_preds, 0).argmax(1).reshape(-1), np.concatenate(all_tags, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDa6MrdCkIHx"
      },
      "source": [
        "Определяем функцию валидации модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Vm_3DZiX6TbJ"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_tags = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text = batch[0]\n",
        "            tags = batch[1]\n",
        "            \n",
        "            predictions = model(text)\n",
        "\n",
        "            all_preds.append(predictions.detach().cpu().numpy())\n",
        "            all_tags.append(tags.detach().cpu().numpy())\n",
        "            \n",
        "            loss = criterion(predictions, tags)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), np.concatenate(all_preds, 0).argmax(1).reshape(-1), np.concatenate(all_tags, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqToCQgWkMzB"
      },
      "source": [
        "Определяем функцию для подсчета времени выполнения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "snT_IcJe6W-5"
      },
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhu1W_GEmEgo"
      },
      "source": [
        "Задаем параметры для `classification_report`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GasDGzLAZk_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e2f079-ad4c-444e-ce57-12885dbb4f9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
            "['NOUN', 'VERB', 'INFN', 'PRCL', 'PREP', 'ADJF', 'NPRO', 'ADVB', 'PRED', 'CONJ', 'Name', 'Surn', 'PRTF', 'COMP', 'NUMR', 'UNKN', 'Patr', 'INTJ', 'PRTS', 'GRND', 'Geox', 'ADJS']\n"
          ]
        }
      ],
      "source": [
        "cr_labels = []\n",
        "cr_names = []\n",
        "\n",
        "for name, label in ttoi.items():\n",
        "    cr_labels.append(label)\n",
        "    cr_names.append(name)\n",
        "\n",
        "print(cr_labels)\n",
        "print(cr_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIdF6trwmLPg"
      },
      "source": [
        "Обучаем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "LvO_nXHl6fBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4921296e-2c51-4147-d9b3-0f05b6409da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.552\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.87      0.93      0.90    356194\n",
            "        VERB       0.69      0.86      0.76     96780\n",
            "        INFN       0.66      0.45      0.53     25493\n",
            "        PRCL       0.87      0.84      0.86     32664\n",
            "        PREP       0.97      0.98      0.98    130292\n",
            "        ADJF       0.82      0.85      0.83    163014\n",
            "        NPRO       0.85      0.84      0.85     32607\n",
            "        ADVB       0.77      0.71      0.74     41082\n",
            "        PRED       0.83      0.62      0.71      3576\n",
            "        CONJ       0.93      0.95      0.94     96608\n",
            "        Name       0.63      0.51      0.56     12913\n",
            "        Surn       0.57      0.38      0.46      9474\n",
            "        PRTF       0.46      0.12      0.19     17090\n",
            "        COMP       0.61      0.32      0.42      2589\n",
            "        NUMR       0.87      0.74      0.80      5613\n",
            "        UNKN       0.47      0.36      0.41     23719\n",
            "        Patr       0.69      0.26      0.38       853\n",
            "        INTJ       0.60      0.34      0.43      1778\n",
            "        PRTS       0.57      0.26      0.36      7456\n",
            "        GRND       0.16      0.00      0.00      4983\n",
            "        Geox       0.83      0.68      0.75     15794\n",
            "        ADJS       0.55      0.22      0.31      8668\n",
            "\n",
            "    accuracy                           0.84   1089240\n",
            "   macro avg       0.69      0.56      0.60   1089240\n",
            "weighted avg       0.82      0.84      0.82   1089240\n",
            "\n",
            "\t Val Loss: 0.340\n",
            "Epoch: 02 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.93      0.95      0.94    356194\n",
            "        VERB       0.74      0.89      0.81     96780\n",
            "        INFN       0.75      0.53      0.62     25493\n",
            "        PRCL       0.93      0.90      0.92     32664\n",
            "        PREP       0.98      0.99      0.99    130292\n",
            "        ADJF       0.88      0.90      0.89    163014\n",
            "        NPRO       0.89      0.89      0.89     32607\n",
            "        ADVB       0.89      0.85      0.87     41082\n",
            "        PRED       0.89      0.81      0.85      3576\n",
            "        CONJ       0.97      0.98      0.97     96608\n",
            "        Name       0.75      0.63      0.68     12913\n",
            "        Surn       0.69      0.56      0.62      9474\n",
            "        PRTF       0.55      0.25      0.35     17090\n",
            "        COMP       0.71      0.54      0.61      2589\n",
            "        NUMR       0.92      0.91      0.91      5613\n",
            "        UNKN       0.51      0.58      0.54     23719\n",
            "        Patr       0.77      0.55      0.64       853\n",
            "        INTJ       0.77      0.67      0.72      1778\n",
            "        PRTS       0.60      0.43      0.50      7456\n",
            "        GRND       0.33      0.01      0.01      4983\n",
            "        Geox       0.89      0.81      0.85     15794\n",
            "        ADJS       0.64      0.40      0.49      8668\n",
            "\n",
            "    accuracy                           0.89   1089240\n",
            "   macro avg       0.77      0.68      0.71   1089240\n",
            "weighted avg       0.88      0.89      0.88   1089240\n",
            "\n",
            "\t Val Loss: 0.295\n",
            "Epoch: 03 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.320\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.95      0.96      0.96    356194\n",
            "        VERB       0.76      0.91      0.83     96780\n",
            "        INFN       0.78      0.56      0.65     25493\n",
            "        PRCL       0.93      0.91      0.92     32664\n",
            "        PREP       0.98      0.99      0.99    130292\n",
            "        ADJF       0.90      0.92      0.91    163014\n",
            "        NPRO       0.90      0.90      0.90     32607\n",
            "        ADVB       0.92      0.88      0.90     41082\n",
            "        PRED       0.90      0.83      0.86      3576\n",
            "        CONJ       0.97      0.98      0.98     96608\n",
            "        Name       0.80      0.69      0.74     12913\n",
            "        Surn       0.76      0.66      0.71      9474\n",
            "        PRTF       0.59      0.32      0.42     17090\n",
            "        COMP       0.74      0.57      0.64      2589\n",
            "        NUMR       0.93      0.93      0.93      5613\n",
            "        UNKN       0.55      0.66      0.60     23719\n",
            "        Patr       0.85      0.64      0.73       853\n",
            "        INTJ       0.79      0.72      0.76      1778\n",
            "        PRTS       0.63      0.50      0.56      7456\n",
            "        GRND       0.38      0.02      0.03      4983\n",
            "        Geox       0.92      0.85      0.88     15794\n",
            "        ADJS       0.67      0.47      0.55      8668\n",
            "\n",
            "    accuracy                           0.90   1089240\n",
            "   macro avg       0.80      0.72      0.75   1089240\n",
            "weighted avg       0.90      0.90      0.90   1089240\n",
            "\n",
            "\t Val Loss: 0.268\n",
            "Epoch: 04 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.287\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.96      0.97      0.97    356194\n",
            "        VERB       0.77      0.91      0.83     96780\n",
            "        INFN       0.79      0.57      0.67     25493\n",
            "        PRCL       0.94      0.92      0.93     32664\n",
            "        PREP       0.98      0.99      0.99    130292\n",
            "        ADJF       0.91      0.93      0.92    163014\n",
            "        NPRO       0.91      0.90      0.90     32607\n",
            "        ADVB       0.93      0.90      0.91     41082\n",
            "        PRED       0.90      0.84      0.87      3576\n",
            "        CONJ       0.97      0.98      0.98     96608\n",
            "        Name       0.84      0.73      0.78     12913\n",
            "        Surn       0.82      0.71      0.76      9474\n",
            "        PRTF       0.62      0.36      0.46     17090\n",
            "        COMP       0.75      0.58      0.66      2589\n",
            "        NUMR       0.94      0.94      0.94      5613\n",
            "        UNKN       0.60      0.73      0.66     23719\n",
            "        Patr       0.85      0.71      0.77       853\n",
            "        INTJ       0.79      0.75      0.77      1778\n",
            "        PRTS       0.65      0.53      0.59      7456\n",
            "        GRND       0.44      0.03      0.05      4983\n",
            "        Geox       0.93      0.87      0.90     15794\n",
            "        ADJS       0.69      0.51      0.58      8668\n",
            "\n",
            "    accuracy                           0.91   1089240\n",
            "   macro avg       0.82      0.74      0.77   1089240\n",
            "weighted avg       0.91      0.91      0.91   1089240\n",
            "\n",
            "\t Val Loss: 0.253\n",
            "Epoch: 05 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.264\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.97      0.97      0.97    356194\n",
            "        VERB       0.78      0.92      0.84     96780\n",
            "        INFN       0.81      0.58      0.68     25493\n",
            "        PRCL       0.94      0.92      0.93     32664\n",
            "        PREP       0.98      0.99      0.99    130292\n",
            "        ADJF       0.92      0.94      0.93    163014\n",
            "        NPRO       0.91      0.90      0.91     32607\n",
            "        ADVB       0.94      0.91      0.92     41082\n",
            "        PRED       0.91      0.84      0.87      3576\n",
            "        CONJ       0.97      0.98      0.98     96608\n",
            "        Name       0.87      0.76      0.81     12913\n",
            "        Surn       0.85      0.75      0.80      9474\n",
            "        PRTF       0.64      0.40      0.49     17090\n",
            "        COMP       0.76      0.61      0.68      2589\n",
            "        NUMR       0.94      0.94      0.94      5613\n",
            "        UNKN       0.65      0.78      0.71     23719\n",
            "        Patr       0.87      0.75      0.81       853\n",
            "        INTJ       0.81      0.77      0.79      1778\n",
            "        PRTS       0.68      0.55      0.61      7456\n",
            "        GRND       0.44      0.04      0.07      4983\n",
            "        Geox       0.94      0.88      0.91     15794\n",
            "        ADJS       0.70      0.54      0.61      8668\n",
            "\n",
            "    accuracy                           0.92   1089240\n",
            "   macro avg       0.83      0.76      0.78   1089240\n",
            "weighted avg       0.92      0.92      0.92   1089240\n",
            "\n",
            "\t Val Loss: 0.243\n",
            "Epoch: 06 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.246\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.98      0.98      0.98    356194\n",
            "        VERB       0.78      0.92      0.85     96780\n",
            "        INFN       0.81      0.59      0.68     25493\n",
            "        PRCL       0.94      0.92      0.93     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.93      0.95      0.94    163014\n",
            "        NPRO       0.91      0.91      0.91     32607\n",
            "        ADVB       0.94      0.91      0.93     41082\n",
            "        PRED       0.91      0.85      0.88      3576\n",
            "        CONJ       0.97      0.98      0.98     96608\n",
            "        Name       0.89      0.77      0.83     12913\n",
            "        Surn       0.87      0.78      0.83      9474\n",
            "        PRTF       0.65      0.43      0.52     17090\n",
            "        COMP       0.76      0.63      0.69      2589\n",
            "        NUMR       0.95      0.95      0.95      5613\n",
            "        UNKN       0.71      0.83      0.76     23719\n",
            "        Patr       0.89      0.78      0.83       853\n",
            "        INTJ       0.80      0.77      0.79      1778\n",
            "        PRTS       0.68      0.56      0.62      7456\n",
            "        GRND       0.48      0.04      0.08      4983\n",
            "        Geox       0.95      0.90      0.92     15794\n",
            "        ADJS       0.71      0.56      0.63      8668\n",
            "\n",
            "    accuracy                           0.93   1089240\n",
            "   macro avg       0.84      0.77      0.80   1089240\n",
            "weighted avg       0.92      0.93      0.92   1089240\n",
            "\n",
            "\t Val Loss: 0.234\n",
            "Epoch: 07 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.232\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.98      0.98      0.98    356194\n",
            "        VERB       0.79      0.93      0.85     96780\n",
            "        INFN       0.82      0.60      0.69     25493\n",
            "        PRCL       0.94      0.92      0.93     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.93      0.95      0.94    163014\n",
            "        NPRO       0.92      0.91      0.91     32607\n",
            "        ADVB       0.95      0.92      0.93     41082\n",
            "        PRED       0.92      0.85      0.88      3576\n",
            "        CONJ       0.97      0.98      0.98     96608\n",
            "        Name       0.90      0.79      0.84     12913\n",
            "        Surn       0.89      0.81      0.85      9474\n",
            "        PRTF       0.67      0.45      0.54     17090\n",
            "        COMP       0.78      0.64      0.70      2589\n",
            "        NUMR       0.94      0.95      0.94      5613\n",
            "        UNKN       0.76      0.86      0.80     23719\n",
            "        Patr       0.91      0.80      0.85       853\n",
            "        INTJ       0.81      0.79      0.80      1778\n",
            "        PRTS       0.69      0.58      0.63      7456\n",
            "        GRND       0.49      0.05      0.09      4983\n",
            "        Geox       0.95      0.90      0.93     15794\n",
            "        ADJS       0.72      0.58      0.64      8668\n",
            "\n",
            "    accuracy                           0.93   1089240\n",
            "   macro avg       0.85      0.78      0.81   1089240\n",
            "weighted avg       0.93      0.93      0.93   1089240\n",
            "\n",
            "\t Val Loss: 0.231\n",
            "Epoch: 08 | Epoch Time: 0m 37s\n",
            "\tTrain Loss: 0.221\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.98      0.98      0.98    356194\n",
            "        VERB       0.79      0.93      0.86     96780\n",
            "        INFN       0.83      0.61      0.70     25493\n",
            "        PRCL       0.94      0.92      0.93     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.94      0.96      0.95    163014\n",
            "        NPRO       0.92      0.91      0.91     32607\n",
            "        ADVB       0.95      0.93      0.94     41082\n",
            "        PRED       0.92      0.85      0.88      3576\n",
            "        CONJ       0.98      0.98      0.98     96608\n",
            "        Name       0.91      0.81      0.85     12913\n",
            "        Surn       0.90      0.83      0.87      9474\n",
            "        PRTF       0.67      0.47      0.55     17090\n",
            "        COMP       0.77      0.64      0.70      2589\n",
            "        NUMR       0.94      0.95      0.95      5613\n",
            "        UNKN       0.79      0.88      0.83     23719\n",
            "        Patr       0.92      0.83      0.87       853\n",
            "        INTJ       0.81      0.79      0.80      1778\n",
            "        PRTS       0.70      0.59      0.64      7456\n",
            "        GRND       0.50      0.05      0.10      4983\n",
            "        Geox       0.96      0.91      0.93     15794\n",
            "        ADJS       0.73      0.59      0.65      8668\n",
            "\n",
            "    accuracy                           0.93   1089240\n",
            "   macro avg       0.86      0.79      0.81   1089240\n",
            "weighted avg       0.93      0.93      0.93   1089240\n",
            "\n",
            "\t Val Loss: 0.228\n",
            "Epoch: 09 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.211\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.98      0.98      0.98    356194\n",
            "        VERB       0.80      0.93      0.86     96780\n",
            "        INFN       0.83      0.61      0.70     25493\n",
            "        PRCL       0.94      0.93      0.93     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.94      0.96      0.95    163014\n",
            "        NPRO       0.92      0.91      0.91     32607\n",
            "        ADVB       0.95      0.93      0.94     41082\n",
            "        PRED       0.92      0.85      0.89      3576\n",
            "        CONJ       0.98      0.99      0.98     96608\n",
            "        Name       0.91      0.82      0.87     12913\n",
            "        Surn       0.91      0.85      0.88      9474\n",
            "        PRTF       0.68      0.48      0.57     17090\n",
            "        COMP       0.79      0.65      0.71      2589\n",
            "        NUMR       0.95      0.96      0.95      5613\n",
            "        UNKN       0.83      0.90      0.86     23719\n",
            "        Patr       0.94      0.85      0.89       853\n",
            "        INTJ       0.82      0.80      0.81      1778\n",
            "        PRTS       0.71      0.61      0.65      7456\n",
            "        GRND       0.52      0.06      0.11      4983\n",
            "        Geox       0.96      0.91      0.94     15794\n",
            "        ADJS       0.73      0.60      0.66      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.86      0.80      0.82   1089240\n",
            "weighted avg       0.93      0.94      0.93   1089240\n",
            "\n",
            "\t Val Loss: 0.225\n",
            "Epoch: 10 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.204\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.98      0.98      0.98    356194\n",
            "        VERB       0.80      0.93      0.86     96780\n",
            "        INFN       0.83      0.62      0.71     25493\n",
            "        PRCL       0.94      0.93      0.93     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.94      0.96      0.95    163014\n",
            "        NPRO       0.92      0.91      0.92     32607\n",
            "        ADVB       0.95      0.93      0.94     41082\n",
            "        PRED       0.92      0.85      0.89      3576\n",
            "        CONJ       0.98      0.98      0.98     96608\n",
            "        Name       0.92      0.83      0.87     12913\n",
            "        Surn       0.92      0.86      0.89      9474\n",
            "        PRTF       0.69      0.50      0.58     17090\n",
            "        COMP       0.78      0.65      0.71      2589\n",
            "        NUMR       0.95      0.96      0.95      5613\n",
            "        UNKN       0.85      0.91      0.88     23719\n",
            "        Patr       0.94      0.85      0.90       853\n",
            "        INTJ       0.82      0.82      0.82      1778\n",
            "        PRTS       0.71      0.61      0.66      7456\n",
            "        GRND       0.50      0.06      0.11      4983\n",
            "        Geox       0.96      0.92      0.94     15794\n",
            "        ADJS       0.73      0.61      0.67      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.86      0.80      0.82   1089240\n",
            "weighted avg       0.94      0.94      0.94   1089240\n",
            "\n",
            "\t Val Loss: 0.222\n",
            "Epoch: 11 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.198\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.99      0.98      0.98    356194\n",
            "        VERB       0.80      0.93      0.86     96780\n",
            "        INFN       0.83      0.62      0.71     25493\n",
            "        PRCL       0.94      0.93      0.93     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.94      0.96      0.95    163014\n",
            "        NPRO       0.92      0.91      0.92     32607\n",
            "        ADVB       0.96      0.93      0.95     41082\n",
            "        PRED       0.92      0.85      0.88      3576\n",
            "        CONJ       0.98      0.99      0.98     96608\n",
            "        Name       0.92      0.84      0.88     12913\n",
            "        Surn       0.93      0.88      0.90      9474\n",
            "        PRTF       0.69      0.51      0.59     17090\n",
            "        COMP       0.80      0.67      0.73      2589\n",
            "        NUMR       0.95      0.96      0.95      5613\n",
            "        UNKN       0.88      0.92      0.90     23719\n",
            "        Patr       0.95      0.86      0.90       853\n",
            "        INTJ       0.82      0.83      0.82      1778\n",
            "        PRTS       0.72      0.62      0.67      7456\n",
            "        GRND       0.53      0.07      0.12      4983\n",
            "        Geox       0.97      0.92      0.94     15794\n",
            "        ADJS       0.74      0.63      0.68      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.87      0.81      0.83   1089240\n",
            "weighted avg       0.94      0.94      0.94   1089240\n",
            "\n",
            "\t Val Loss: 0.218\n",
            "Epoch: 12 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.193\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.99      0.98      0.99    356194\n",
            "        VERB       0.80      0.94      0.86     96780\n",
            "        INFN       0.83      0.63      0.71     25493\n",
            "        PRCL       0.94      0.93      0.94     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.94      0.96      0.95    163014\n",
            "        NPRO       0.92      0.91      0.92     32607\n",
            "        ADVB       0.96      0.94      0.95     41082\n",
            "        PRED       0.92      0.86      0.89      3576\n",
            "        CONJ       0.98      0.99      0.98     96608\n",
            "        Name       0.93      0.84      0.88     12913\n",
            "        Surn       0.93      0.89      0.91      9474\n",
            "        PRTF       0.70      0.51      0.59     17090\n",
            "        COMP       0.79      0.67      0.72      2589\n",
            "        NUMR       0.95      0.96      0.95      5613\n",
            "        UNKN       0.89      0.93      0.91     23719\n",
            "        Patr       0.95      0.87      0.91       853\n",
            "        INTJ       0.82      0.83      0.83      1778\n",
            "        PRTS       0.72      0.63      0.67      7456\n",
            "        GRND       0.53      0.07      0.13      4983\n",
            "        Geox       0.97      0.93      0.95     15794\n",
            "        ADJS       0.74      0.63      0.68      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.87      0.81      0.83   1089240\n",
            "weighted avg       0.94      0.94      0.94   1089240\n",
            "\n",
            "\t Val Loss: 0.217\n",
            "Epoch: 13 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.189\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.99      0.99      0.99    356194\n",
            "        VERB       0.81      0.94      0.87     96780\n",
            "        INFN       0.83      0.63      0.72     25493\n",
            "        PRCL       0.95      0.93      0.94     32664\n",
            "        PREP       0.98      1.00      0.99    130292\n",
            "        ADJF       0.95      0.97      0.96    163014\n",
            "        NPRO       0.92      0.92      0.92     32607\n",
            "        ADVB       0.96      0.94      0.95     41082\n",
            "        PRED       0.92      0.86      0.89      3576\n",
            "        CONJ       0.98      0.99      0.98     96608\n",
            "        Name       0.93      0.85      0.89     12913\n",
            "        Surn       0.93      0.90      0.92      9474\n",
            "        PRTF       0.71      0.54      0.61     17090\n",
            "        COMP       0.79      0.67      0.73      2589\n",
            "        NUMR       0.95      0.96      0.95      5613\n",
            "        UNKN       0.90      0.93      0.92     23719\n",
            "        Patr       0.95      0.88      0.92       853\n",
            "        INTJ       0.82      0.83      0.83      1778\n",
            "        PRTS       0.73      0.63      0.68      7456\n",
            "        GRND       0.53      0.08      0.14      4983\n",
            "        Geox       0.97      0.93      0.95     15794\n",
            "        ADJS       0.75      0.65      0.69      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.88      0.82      0.84   1089240\n",
            "weighted avg       0.94      0.94      0.94   1089240\n",
            "\n",
            "\t Val Loss: 0.214\n",
            "Epoch: 14 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.185\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.99      0.99      0.99    356194\n",
            "        VERB       0.81      0.94      0.87     96780\n",
            "        INFN       0.83      0.64      0.72     25493\n",
            "        PRCL       0.95      0.93      0.94     32664\n",
            "        PREP       0.99      1.00      0.99    130292\n",
            "        ADJF       0.95      0.97      0.96    163014\n",
            "        NPRO       0.93      0.92      0.92     32607\n",
            "        ADVB       0.96      0.94      0.95     41082\n",
            "        PRED       0.92      0.86      0.89      3576\n",
            "        CONJ       0.98      0.99      0.98     96608\n",
            "        Name       0.93      0.85      0.89     12913\n",
            "        Surn       0.94      0.91      0.92      9474\n",
            "        PRTF       0.71      0.53      0.61     17090\n",
            "        COMP       0.79      0.69      0.74      2589\n",
            "        NUMR       0.95      0.96      0.96      5613\n",
            "        UNKN       0.92      0.93      0.92     23719\n",
            "        Patr       0.95      0.89      0.92       853\n",
            "        INTJ       0.82      0.84      0.83      1778\n",
            "        PRTS       0.73      0.64      0.68      7456\n",
            "        GRND       0.54      0.08      0.14      4983\n",
            "        Geox       0.97      0.93      0.95     15794\n",
            "        ADJS       0.75      0.65      0.70      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.88      0.82      0.84   1089240\n",
            "weighted avg       0.94      0.94      0.94   1089240\n",
            "\n",
            "\t Val Loss: 0.214\n",
            "Epoch: 15 | Epoch Time: 0m 36s\n",
            "\tTrain Loss: 0.181\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.99      0.99      0.99    356194\n",
            "        VERB       0.81      0.94      0.87     96780\n",
            "        INFN       0.83      0.64      0.73     25493\n",
            "        PRCL       0.95      0.93      0.94     32664\n",
            "        PREP       0.99      1.00      0.99    130292\n",
            "        ADJF       0.95      0.97      0.96    163014\n",
            "        NPRO       0.93      0.92      0.92     32607\n",
            "        ADVB       0.96      0.94      0.95     41082\n",
            "        PRED       0.92      0.86      0.89      3576\n",
            "        CONJ       0.98      0.99      0.98     96608\n",
            "        Name       0.93      0.86      0.89     12913\n",
            "        Surn       0.94      0.91      0.92      9474\n",
            "        PRTF       0.71      0.55      0.62     17090\n",
            "        COMP       0.80      0.69      0.74      2589\n",
            "        NUMR       0.95      0.96      0.95      5613\n",
            "        UNKN       0.92      0.94      0.93     23719\n",
            "        Patr       0.95      0.89      0.92       853\n",
            "        INTJ       0.83      0.85      0.84      1778\n",
            "        PRTS       0.73      0.64      0.68      7456\n",
            "        GRND       0.53      0.09      0.15      4983\n",
            "        Geox       0.97      0.94      0.95     15794\n",
            "        ADJS       0.75      0.66      0.70      8668\n",
            "\n",
            "    accuracy                           0.94   1089240\n",
            "   macro avg       0.88      0.82      0.84   1089240\n",
            "weighted avg       0.94      0.94      0.94   1089240\n",
            "\n",
            "\t Val Loss: 0.214\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 15\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_preds, train_tags = train(model, dataloader_train, optimizer, criterion)\n",
        "    valid_loss, _, __ = evaluate(model, dataloader_val, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "\n",
        "    print(classification_report(train_tags, train_preds, labels=cr_labels, target_names=cr_names))\n",
        "\n",
        "    print(f'\\t Val Loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru-b_srcmoiJ"
      },
      "source": [
        "Тестируем модель на отложенной выборке"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "1ZlL44226iiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99abba69-05ec-444a-81bb-b16d04caaacd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.214\n",
            "[4 0 5 ... 0 5 4]\n",
            "[4 0 5 ... 0 5 4]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        NOUN       0.97      0.98      0.98    101770\n",
            "        VERB       0.80      0.92      0.86     27652\n",
            "        INFN       0.80      0.65      0.71      7284\n",
            "        PRCL       0.95      0.94      0.94      9333\n",
            "        PREP       0.98      1.00      0.99     37226\n",
            "        ADJF       0.93      0.96      0.94     46575\n",
            "        NPRO       0.92      0.93      0.92      9316\n",
            "        ADVB       0.97      0.93      0.95     11738\n",
            "        PRED       0.89      0.90      0.90      1022\n",
            "        CONJ       0.98      0.99      0.98     27602\n",
            "        Name       0.96      0.82      0.89      3689\n",
            "        Surn       0.94      0.87      0.90      2707\n",
            "        PRTF       0.76      0.39      0.52      4883\n",
            "        COMP       0.72      0.77      0.75       739\n",
            "        NUMR       0.94      0.99      0.96      1603\n",
            "        UNKN       0.77      0.73      0.75      6777\n",
            "        Patr       1.00      0.85      0.92       243\n",
            "        INTJ       0.86      0.91      0.89       508\n",
            "        PRTS       0.61      0.72      0.66      2131\n",
            "        GRND       0.62      0.05      0.10      1424\n",
            "        Geox       0.97      0.90      0.94      4513\n",
            "        ADJS       0.78      0.61      0.68      2477\n",
            "\n",
            "    accuracy                           0.93    311212\n",
            "   macro avg       0.87      0.81      0.82    311212\n",
            "weighted avg       0.93      0.93      0.93    311212\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('tut2-model.pt'))\n",
        "\n",
        "test_loss, test_preds, test_tags = evaluate(model, dataloader_test, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f}')\n",
        "\n",
        "print(test_preds[10:])\n",
        "print(test_tags[10:])\n",
        "\n",
        "print(classification_report(test_tags, test_preds, labels=cr_labels, target_names=cr_names))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end_full_measure = time.perf_counter()"
      ],
      "metadata": {
        "id": "5_ZzMcOdIhiN"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Полное время выполнения:', end_full_measure - start_full_measure)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6ShesmlIjPl",
        "outputId": "1fcd5ac7-8841-4798-e916-3650c011ab68"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Полное время выполнения: 973.8670258940001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYlsiBEXoWRJ"
      },
      "source": [
        "# Часть 4. Использование модели keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUVFr34LofQR"
      },
      "source": [
        "Импортируем необходимые библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "BxAn3VhawXcN"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import losses\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, Embedding, Dropout, Reshape\n",
        "import time\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.math import argmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "pwbm-rp9zaCN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf88d911-e2b6-4bc7-bc07-8de26d695bb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 0], [0, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11]]\n",
            "[0, 0, 1, 2, 0, 1, 3, 0, 0, 4]\n"
          ]
        }
      ],
      "source": [
        "print(x[:10])\n",
        "print(y[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKVwKzFQp8II"
      },
      "source": [
        "Создаем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "AI7kIMuswi9t"
      },
      "outputs": [],
      "source": [
        "#создание модели          \n",
        "def create_model(sq, num_words, size, num_classes):\n",
        "    inp = Input(shape = (sq, ), dtype = 'int32')\n",
        "    e_weights = make_e_weights()\n",
        "    x = Embedding(num_words, output_dim = size, input_length = sq, \n",
        "                weights = [e_weights], trainable = True)(inp)\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(size, activation = 'relu', use_bias = True)(x)\n",
        "    output = Dense(num_classes, activation = 'softmax', use_bias = True)(x)\n",
        "    model = Model(inp, output)\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eaB_-hHp-Ow"
      },
      "source": [
        "Определяем функцию-обертку для `clasification_report`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "EQoR4uwSqvZH"
      },
      "outputs": [],
      "source": [
        "class Metrics(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.data = []\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        print(self.validation_data)\n",
        "        X_val, y_val = self.batch[0], self.batch[1]\n",
        "        y_predict = model.predict(X_val)\n",
        "\n",
        "        y_predict = argmax(y_predict, 1)\n",
        "\n",
        "        self.data.append(classification_report(y_val.numpy(), y_predict.numpy(), labels=cr_labels, target_names=cr_names))\n",
        "\n",
        "    def get_data(self):\n",
        "        return self.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-OC6ykJqEhx"
      },
      "source": [
        "Обучаем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "E6lGdb2Xwpxl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "outputId": "4c5cb0b3-c9ad-453d-c688-1607958ee08d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3)]               0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 3, 30)             1921200   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 90)                0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 90)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 30)                2730      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 22)                682       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,924,612\n",
            "Trainable params: 1,924,612\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "9118/9118 - 175s - loss: 0.7188 - accuracy: 0.7882 - val_loss: 0.4321 - val_accuracy: 0.8680 - 175s/epoch - 19ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-5dff224fcab5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstartTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Full time:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#обучение НС\n",
        "model = create_model(3, len(stoi), 30, len(ttoi))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = losses.sparse_categorical_crossentropy, metrics = ['accuracy'], run_eagerly=True)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25)\n",
        "\n",
        "startTime = time.time()\n",
        "metrics = Metrics()\n",
        "history = model.fit(x_train, y_train, batch_size = 128, epochs = 15, verbose = 2, validation_data = (x_test, y_test))\n",
        "print('Full time:', time.time() - startTime)\n",
        "\n",
        "pred = model.predict(x_test, batch_size=32, verbose=2)\n",
        "predicted = np.argmax(pred, axis=1)\n",
        "report = classification_report(y_test, predicted, labels=cr_labels, target_names=cr_names)\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "src_w2v.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
